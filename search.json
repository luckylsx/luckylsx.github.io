[{"title":"透视http协议(2)","url":"/2021/07/04/透视http协议(2)/","content":"\n## 键入网址再按下回车，后面究竟发生了什么？\n\n### 使用 IP 地址访问 Web 服务器\n\n1. 浏览器从地址栏的输入中获得服务器的IP 地址和端口号；\n2. 浏览器用 TCP 的三次握手与服务器建立连接；\n3. 浏览器向服务器发送拼好的报文；\n4. 服务器收到报文后处理请求，同样拼好报文再发给浏览器；\n5. 浏览器解析报文，渲染输出页面。\n\n### 使用域名访问 Web 服务器\n\n首先会经过DNS解析，浏览器首先看一下自己的缓存里有没有，如果没有就向操作系统的缓存要，还没有就检查本机域名解析文件 hosts，也就是 hosts 文件，windows为“C:\\WINDOWS\\system32\\drivers\\etc\\hosts”。\n\nDNS解析流程：\n\n先查浏览器缓存，然后是系统缓存-＞hosts文件-＞局域网域名服务器-＞广域网域名服务器-＞顶级域名服务器-＞根域名服务器。\n\n### http 报文\n\nHTTP 协议在规范文档里详细定义了报文的格式，规定了组成部分，解析规则，还有处理策略，所以可以在 TCP/IP 层之上实现更灵活丰富的功能，例如连接控制，缓存管理、数据编码、内容协商等等。\n\n#### 报文结构\n\nTCP 报文来看，它在实际要传输的数据之前附加了一个 20 字节的头部数据，存储 TCP 协议必须的额外信息，例如发送方的端口号、接收方的端口号、包序号、标志位等等。\n\n有了这个附加的 TCP 头，数据包才能够正确传输，到了目的地后把头部去掉，就可以拿到真正的数据。\n\n<img src=\"/images/http/gk/tcp-header.webp\" art=\"http-header\" width=\"500px\">\n\nHTTP 协议也是与 TCP/UDP 类似，同样也需要在实际传输的数据前附加一些头数据，不过与 TCP/UDP 不同的是，它是一个“纯文本”的协议，所以头数据都是 ASCII 码的文本，可以很容易地用肉眼阅读，不用借助程序解析也能够看懂。\n\nHTTP 协议的请求报文和响应报文的结构基本相同，由三大部分组成：\n\n1. 起始行（start line）：描述请求或响应的基本信息；\n2. 头部字段集合（header）：使用 key-value 形式更详细地说明报文；\n3. 消息正文（entity）：实际传输的数据，它不一定是纯文本，可以是图片、视频等二进制数据。\n\n这其中前两部分起始行和头部字段经常又合称为“请求头”或“响应头”，消息正文又称为“实体”，但与“header”对应，很多时候就直接称为“body”。\n\nHTTP 协议规定报文必须有 header，但可以没有 body，而且在 header 之后必须要有一个“空行”，也就是“CRLF”，十六进制的“0D0A”。\n\n所以，一个完整的 HTTP 报文就像是下图的这个样子，注意在 header 和 body 之间有一个“空行”。\n\n<img src=\"/images/http/gk/http-header.webp\" art=\"http-header\" width=\"500px\">\n\nhttp header头\n\n<img src=\"/images/http/gk/http-header-code.webp\" art=\"http-header\" width=\"500px\">\n\n第一行“GET / HTTP/1.1”就是请求行，而后面的“Host”“Connection”等等都属于 header，报文的最后是一个空白行结束，没有 body。\n\n##### 请求行\n\n请求行由三部分构成：\n\n1. 请求方法：是一个动词，如 GET/POST，表示对资源的操作；\n2. 请求目标：通常是一个 URI，标记了请求方法要操作的资源；\n3. 版本号：表示报文使用的 HTTP 协议版本。\n\n这三个部分通常使用空格（space）来分隔，最后要用 CRLF 换行表示结束。\n\n<img src=\"/images/http/gk/request-line.webp\" art=\"http-header\" width=\"500px\">\n\n```\nGET / HTTP/1.1\n```\n\n在这个请求行里，“GET”是请求方法，“/”是请求目标，“HTTP/1.1”是版本号，把这三部分连起来，意思就是“服务器你好，我想获取网站根目录下的默认文件，我用的协议版本号是 1.1，请不要用 1.0 或者 2.0 回复我。”\n\n##### 状态行\n\n意思是服务器响应的状态。\n\n状态行也是由三部分构成:\n\n1. 版本号：表示报文使用的 HTTP 协议版本；\n2. 状态码：一个三位数，用代码的形式表示处理的结果，比如 200 是成功，500 是服务器错误；\n3. 原因：作为数字状态码补充，是更详细的解释文字，帮助人理解原因。\n\n<img src=\"/images/http/gk/status-line.webp\" art=\"status-line\" width=\"500px\">\n\n```\nHTTP/1.1 200 OK\n```\n\n意思就是：“请求完成，这个报文使用的协议版本号是 1.1，状态码是 200，一切 OK。”\n\n##### 头部字段\n\n请求行或状态行再加上头部字段集合就构成了 HTTP 报文里完整的请求头或响应头\n\n如图：\n\n<img src=\"/images/http/gk/request-h.webp\" art=\"request-h\" width=\"500px\">\n<img src=\"/images/http/gk/response-h.webp\" art=\"response-h\" width=\"500px\">\n\n请求头和响应头的结构是基本一样的，唯一的区别是起始行，所以我把请求头和响应头里的字段放在一起介绍。\n\n头部字段是 key-value 的形式，key 和 value 之间用“:”分隔，最后用 CRLF 换行表示字段结束。比如在“Host: 127.0.0.1”这一行里 key 就是“Host”，value 就是“127.0.0.1”。\n\nHTTP 头字段非常灵活，不仅可以使用标准里的 Host、Connection 等已有头，也可以任意添加自定义头，这就给 HTTP 协议带来了无限的扩展可能。\n\n不过使用头字段需要注意下面几点：\n\n1. 字段名不区分大小写，例如“Host”也可以写成“host”，但首字母大写的可读性更好；\n2. 字段名里不允许出现空格，可以使用连字符“-”，但不能使用下划线“_”。例如，“test-name”是合法的字段名，而“test name”“test_name”是不正确的字段名；\n3. 字段名后面必须紧接着“:”，不能有空格，而“:”后的字段值前可以有多个空格；\n4. 字段的顺序是没有意义的，可以任意排列不影响语义；\n5. 字段原则上不能重复，除非这个字段本身的语义允许，例如 Set-Cookie。\n\n##### 常用头字段\n\nHTTP 协议规定了非常多的头部字段，实现各种各样的功能，但基本上可以分为四大类：\n\n1. 通用字段：在请求头和响应头里都可以出现；\n2. 请求字段：仅能出现在请求头里，进一步说明请求信息或者额外的附加条件；\n3. 响应字段：仅能出现在响应头里，补充说明响应报文的信息；\n4. 实体字段：它实际上属于通用字段，但专门描述 body 的额外信息。\n\n首先要说的是 Host 字段，它属于请求字段，只能出现在请求头里，它同时也是唯一一个 HTTP/1.1 规范里要求必须出现的字段，也就是说，如果请求头里没有 Host，那这就是一个错误的报文。\n\n###### Host\n\nHost 字段告诉服务器这个请求应该由哪个主机来处理，当一台计算机上托管了多个虚拟主机的时候，服务器端就需要用 Host 字段来选择，有点像是一个简单的“路由重定向”。\n\n例如在 127.0.0.1 上有三个虚拟主机：“www.chrono.com”“www.metroid.net”和“origin.io”。那么当使用域名的方式访问时，就必须要用 Host 字段来区分这三个 IP 相同但域名不同的网站，否则服务器就会找不到合适的虚拟主机，无法处理。\n\n###### User-Agent\n\nUser-Agent 是请求字段，只出现在请求头里。它使用一个字符串来描述发起 HTTP 请求的客户端，服务器可以依据它来返回最合适此浏览器显示的页面。\n\n但由于历史的原因，User-Agent 非常混乱，每个浏览器都自称是“Mozilla”“Chrome”“Safari”，企图使用这个字段来互相“伪装”，导致 User-Agent 变得越来越长，最终变得毫无意义。\n\n###### Date\n\nDate 字段是一个通用字段，但通常出现在响应头里，表示 HTTP 报文创建的时间，客户端可以使用这个时间再搭配其他字段决定缓存策略。\n\nServer 字段是响应字段，只能出现在响应头里。它告诉客户端当前正在提供 Web 服务的软件名称和版本号，例如在我们的实验环境里它就是“Server: openresty/1.15.8.1”，即使用的是 OpenResty 1.15.8.1。\n\n###### Server\n\nServer 字段也不是必须要出现的，因为这会把服务器的一部分信息暴露给外界，如果这个版本恰好存在 bug，那么黑客就有可能利用 bug 攻陷服务器。所以，有的网站响应头里要么没有这个字段，要么就给出一个完全无关的描述信息。\n\n比如 GitHub，它的 Server 字段里就看不出是使用了 Apache 还是 Nginx，只是显示为“GitHub.com”。\n\n<img src=\"/images/http/gk/github-server.webp\" art=\"github-server\" width=\"500px\">\n\n###### Content-Length\n\nContent-Length，它表示报文里 body 的长度，也就是请求头或响应头空行后面数据的长度。服务器看到这个字段，就知道了后续有多少数据，可以直接接收。如果没有这个字段，那么 body 就是不定长的，需要使用 chunked 方式分段传输。\n\n### 小结\n\n1. HTTP 报文结构由“起始行 + 头部 + 空行 + 实体”组成，简单地说就是“header+body”；2. HTTP 报文可以没有 body，但必须要有 header，而且 header 后也必须要有空行；\n3. 请求头由“请求行 + 头部字段”构成，响应头由“状态行 + 头部字段”构成；\n4. 请求行有三部分：请求方法，请求目标和版本号；\n5. 状态行也有三部分：版本号，状态码和原因字符串；\n6. 头部字段是 key-value 的形式，用“:”分隔，不区分大小写，顺序任意，除了规定的标准头，也可以任意添加自定义字段，实现功能扩展；\n7. HTTP/1.1 里唯一要求必须提供的头字段是 Host，它必须出现在请求头里，标记虚拟主机名。\n\n## 应该如何理解请求方法？\n\n### 标准请求方法\n\n目前 HTTP/1.1 规定了八种方法，单词都必须是大写的形式：\n\n1. GET：获取资源，可以理解为读取或者下载数据；\n2. HEAD：获取资源的元信息；\n3. POST：向资源提交数据，相当于写入或上传数据；\n4. PUT：类似 POST；\n5. DELETE：删除资源；\n6. CONNECT：建立特殊的连接隧道；\n7. OPTIONS：列出可对资源实行的方法；\n8. TRACE：追踪请求 - 响应的传输路径。\n\n### GET/HEAD\n\nGET 方法应该是 HTTP 协议里最知名的请求方法了，也应该是用的最多的\n\n它的含义是请求从服务器获取资源，这个资源既可以是静态的文本、页面、图片、视频，也可以是由 PHP、Java 动态生成的页面或者其他格式的数据。\n\nGET 方法虽然基本动作比较简单，但搭配 URI 和其他头字段就能实现对资源更精细的操作。\n\n例如，在 URI 后使用“#”，就可以在获取页面后直接定位到某个标签所在的位置；使用 If-Modified-Since 字段就变成了“有条件的请求”，仅当资源被修改时才会执行获取动作；使用 Range 字段就是“范围请求”，只获取资源的一部分数据。\n\nHEAD 方法与 GET 方法类似，也是请求从服务器获取资源，服务器的处理机制也是一样的，但服务器不会返回请求的实体数据，只会传回响应头，也就是资源的“元信息”。\n\nHEAD 方法可以看做是 GET 方法的一个“简化版”或者“轻量版”。因为它的响应头与 GET 完全相同，所以可以用在很多并不真正需要资源的场合，避免传输 body 数据的浪费。\n\n### POST/PUT\n\nGET 和 HEAD 方法是从服务器获取数据，而 POST 和 PUT 方法则是相反操作，向 URI 指定的资源提交数据，数据就放在报文的 body 里。\n\nPOST 也是一个经常用到的请求方法，使用频率应该是仅次于 GET，应用的场景也非常多，只要向服务器发送数据，用的大多数都是 POST。\n\nPUT 的作用与 POST 类似，也可以向服务器提交数据，但与 POST 存在微妙的不同，通常 POST 表示的是“新建”“create”的含义，而 PUT 则是“修改”“update”的含义。\n\n在实际应用中，PUT 用到的比较少。而且，因为它与 POST 的语义、功能太过近似，有的服务器甚至就直接禁止使用 PUT 方法，只用 POST 方法上传数据。\n\n```\n➜  ~ telnet www.baidu.com 80\nTrying 180.101.49.12...\nConnected to www.a.shifen.com.\nEscape character is '^]'.\nPOST /10-2 HTTP/1.1\nHost: www.chrono.com\nContent-Length: 17\n\nPOST DATA IS HERE\n\nPUT /10-2 HTTP/1.1\nHost: www.chrono.com\nContent-Length: 16\n\nPUT DATA IS HERE\n```\n\n### 其他方法\n\n* DELETE 方法指示服务器删除资源，因为这个动作危险性太大，所以通常服务器不会执行真正的删除操作，而是对资源做一个删除标记。当然，更多的时候服务器就直接不处理 DELETE 请求。\n* CONNECT 是一个比较特殊的方法，要求服务器为客户端和另一台远程服务器建立一条特殊的连接隧道，这时 Web 服务器在中间充当了代理的角色。\n* OPTIONS 方法要求服务器列出可对资源实行的操作方法，在响应头的 Allow 字段里返回。它的功能很有限，用处也不大，有的服务器（例如 Nginx）干脆就没有实现对它的支持。\n* TRACE 方法多用于对 HTTP 链路的测试或诊断，可以显示出请求 - 响应的传输路径。它的本意是好的，但存在漏洞，会泄漏网站的信息，所以 Web 服务器通常也是禁止使用。\n\n### 扩展方法\n\n虽然 HTTP/1.1 里规定了八种请求方法，但它并没有限制我们只能用这八种方法，这也体现了 HTTP 协议良好的扩展性，我们可以任意添加请求动作，只要请求方和响应方都能理解就行。\n\n此外，还有一些得到了实际应用的请求方法（WebDAV），例如 MKCOL、COPY、MOVE、LOCK、UNLOCK、PATCH 等。\n\n### 安全与幂等\n\n安全与幂等。\n\n在 HTTP 协议里，所谓的“安全”是指请求方法不会“破坏”服务器上的资源，即不会对服务器上的资源造成实质的修改。\n\n按照这个定义，只有 GET 和 HEAD 方法是“安全”的，因为它们是“只读”操作，只要服务器不故意曲解请求方法的处理方式，无论 GET 和 HEAD 操作多少次，服务器上的数据都是“安全的”。\n\n而 POST/PUT/DELETE 操作会修改服务器上的资源，增加或删除数据，所以是“不安全”的。\n\n所谓的“幂等”实际上是一个数学用语，被借用到了 HTTP 协议里，意思是多次执行相同的操作，结果也都是相同的，即多次“幂”后结果“相等”。\n\n很显然，GET 和 HEAD 既是安全的也是幂等的，DELETE 可以多次删除同一个资源，效果都是“资源不存在”，所以也是幂等的。\n\nPOST 和 PUT 的幂等性质就略费解一点。\n\n按照 RFC 里的语义，POST 是“新增或提交数据”，多次提交数据会创建多个资源，所以不是幂等的；而 PUT 是“替换或更新数据”，多次更新一个资源，资源还是会第一次更新的状态，所以是幂等的。\n\n### 小结\n\n1. 请求方法是客户端发出的、要求服务器执行的、对资源的一种操作；\n2. 请求方法是对服务器的“指示”，真正应如何处理由服务器来决定；\n3. 最常用的请求方法是 GET 和 POST，分别是获取数据和发送数据；\n4. HEAD 方法是轻量级的 GET，用来获取资源的元信息；\n5. PUT 基本上是 POST 的同义词，多用于更新数据；\n6. “安全”与“幂等”是描述请求方法的两个重要属性，具有理论指导意义，可以帮助我们设计系统。","tags":["http","TCP/IP"],"categories":["http"]},{"title":"预测性负载均衡","url":"/2021/07/03/预测性负载均衡/","content":"\nSteve Gury 的“预测性负载均衡：不公平但更快、更健壮”\n\n## 客户端负载均衡方法\n\n* 许多可用的服务器，选择哪一个\n\n### 随机选择\n<!-- more -->\n* 随机选择服务器\n* 随着（永远）时间的推移，所有服务器收到相同数量的请求\n* 在短期内，真的可以给出不平衡的选择\n\n### 轮询调度\n\n* 客户端记住前一个服务器\n* 选择列表中的下一个\n\n### 最小负载\n\n* 客户端跟踪每个服务器上的未完成请求\n* 选择未完成请求数量最少的服务器\n* \\[这听起来像是本地负载最少，客户端不知道服务器上的全局负载\\]\n\n## 负载均衡问题\n\n### 服务器并不完全相同\n\n* 有些服务器可能更隐蔽\n* 轮训调度将请求到这些服务器上，使许多请求非常慢\n* 主负载需求将更少\n\n### 惊群效应\n\n* 新的可用资源被请求轰炸\n* 新可用的资源可能还没有准备好\n* [似乎与 Wikipedia 对 [Thudnering Herd Problem](https://en.wikipedia.org/wiki/Thundering_herd_problem) 的定义不太一样]\n* 轮询和随机不会轰炸新可用的资源\n* 主负载会被轰击\n\n### 异常值\n\n* 服务器可能会遇到问题\n    * 例如 GC 暂停，CPU 峰值阻止处理\n* 轮询将继续打击这些暂时缓慢的服务器\n* 最小负载可能会好一点\n\n### 具有独立状态的多个客户端\n\n* 假设没有协调的全局状态\n* 每个客户端都有服务器负载的视图\n* 最小负载和轮询可能会选择全局加载最少的服务器\n\n## 所有这些方法都有问题\n\n![predictive_load_balancing_matrix](/images/linux/slb/predictive_load_balancing_matrix.png)\n\n* [我认为不是针对最少负载提出的最佳观点]\n\n### 基于延迟的负载平衡\n\n#### 使用观察到的延迟作为负载的度量\n\n**负载 = Predicted_Latency * (#requests + 1)**\n\n* 每个服务器都有一个归因于它的延迟\n* 现在决定服务器取决于响应的预计到达时间\n\n#### 预测延迟\n\n* 响应延迟直方图的中位数（不是平均值）\n![predictive_load_balancing_median_latency](/images/linux/slb/predictive_load_balancing_median_latency.png)\n\n* 比平均水平更稳定\n* 滑动窗口上的直方图以说明最近的服务器更改\n* 当历史数据陈旧时，延迟会衰减（自行下降）\n    * 鼓励访问很久没见过的服务器，以防万一发生了变化\n    * 如果服务器仍然很慢，它会重新提高延迟（一段时间后会再次衰减）\n\n#### 问题和解决方案\n\n* 如何估计新服务器（无历史数据）\n    * 解决方案：试用期预热服务器，建立历史\n* 如果服务器返回错误但响应时间很快怎么办\n    * 解决方案：忽略错误延迟\n    * 解决方案：使用失败响应来处置延迟\n\n#### 快速响应延迟\n\n* 跟踪尚未收到响应的请求\n* 如果响应尚未到达预测的时间，我们可以立即调整开始调整预测负载并继续调整它\n* 如果需要调度其他请求，可以使用调整后的预测负载做出决定（在响应返回之前，或者发生大超时之前）\n![predictive_load_balancing_react_quickly](/images/linux/slb/predictive_load_balancing_react_quickly.png)\n\n* 处理突发事件（GC 暂停、网络分区）时效果很好\n* 需要平均一个中位延迟来检测死机/无响应的服务器\n\n#### 不完美\n\n* 延迟并不总是一个完美的信号\n* 冷服务器的缓慢预热\n    * 由于衰变，冷服务器会不时被访问\n    * 尽管如此，他们在一段时间内的流量会相对较少\n* 伪装成成功的错误混淆了系统\n* 请求分布可能暂时不均匀\n\n## 原文地址\n\n* http://alex-ii.github.io/notes/2019/02/13/predictive_load_balancing.html","tags":["slb"],"categories":["linux"]},{"title":"grpc版本控制","url":"/2021/07/02/grpc版本控制/","content":"\ngrpc服务更改时，应考虑一下内容：\n* 更改会对客户端造成如何影响\n* 应实现支持更改对版本控制策略\n\n### 向后兼容性\n\n<!-- more -->\n\ngrpc协议旨在支持随时间变化的服务。通常grpc服务和方法会不中断的新增内容。非中断性变更允许现有客户端继续工作而不做任何更改。更改或删除grpc服务是中断性变更。grpc服务发生中断性变更时，必须更新和重新部署使用该服务的客户端。\n\n对服务进行非中断性变更有一下好处：\n* 现有客户端继续运行\n* 避免向客户端通知中断性变更并进行更新\n* 只需要记录和维护服务对一个版本\n\n### 非重大变化\n\n在grpc协议级别和二进制级别，这些变更不会中断。\n* 添加新服务\n* 向新服务添加新方法\n* 将字段添加到请求消息 - 添加到请求消息的字段将在服务器上通过默认值（若未设置）进行反序列化。若要实现非中断性变更，当新字段不是由旧客户端设置时，服务必须成功。\n* 将字段添加到响应消息 - 添加到响应消息的字段将反序列化到客户端上消息的未知字段集合中\n* 向枚举添加新值 - 枚举被序列化为数值。新的枚举在客户端反序列化为没有枚举名的枚举值。若要实现非中断性变更，旧客户端在接收新枚举值时必须正确运行。\n\n### 二进制中断性变更\n\n以下变更在grpc协议级别是非中断性变更，但如果客户端升级到最新到.proto协议或客户端程序集，则需要对其进行更新。如果你计划将grpc库发布到NuGet，二进制兼容性很重要。\n\n* 删除字段 - 已删除字段中的值被反序列化为消息的未知类型，这并不是grpc协议中断性变更，但如果客户端升级到最新的协定，则需要对其更新。删除的字段编号不会在将来被意外重用，这点很重要。若要确保不会发生这种情况，请使用protobuf的保留关键字指定已删除的字段名称或者编号。\n* 重命名消息 - 消息名称通常不会在网络上发送，因此这不是grpc协议中断性变更。如果客户端升级到最新的协定，则需要对其进行更新。当消息名称用于标识消息类型时，任何字段都会出现消息名称在网络上发送的情况。\n* 嵌套或取消嵌套 - 消息类型可以嵌套。嵌套或取消嵌套消息将更改其消息名称。更改消息类型的嵌套方式对兼容性的影响与重命名相同。\n* 更改csharp_namespace - 更改csharp_namespace将更改所生成的pb代码类型的命名空间。这并不是grpc协议中断性变更，但如果客户端升级到最新的协定，则需要对其进行更新。\n\n### 协议中断性变更\n\n以下各项是协议和二进制的中断性变更。\n* 重命名字段 - 对于Protobuf内容，字段名只在生成的代码中使用。字段编号用于标识网络上的字段。对于Protobuf来说，重命名字段不是协议性变更。但是，如果服务器正在使用JSON内容，则重命名字段是一个中断性变更。\n* 更改字段数据类型 - 将字段的数据类型更改为[不兼容的类型](https://developers.google.com/protocol-buffers/docs/proto3#updating)将在反序列化消息时导致错误。即使新的数据类型是兼容的，但如果客户端升级到最新的协定，它也可能需要更新以支持新的类型。\n* 更改字段编号 - 对于Protobuf有效负载，字段编号用于标识网络上的字段。\n* 重命名包、服务或方法 - grpc使用包名、服务名和方法名来生成URL。客户端从服务器获取UNIMPLEMENTED状态。\n* 删除服务或方法 - 客户端在调用已删除的方法时从服务器获取UNIMPLEMENTED状态。\n\n### 行为中断性变更\n\n在进行非行为中断性变更时，还需要考虑旧客户端是否可以继续使用新的服务行为。例如，向请求字段添加新字段：\n\n* 它不是协议中断性变更\n* 如果未设置新字段，则在服务器上返回错误状态对于旧客户端来说是一个中断性变更。\n\n行为兼容性由应用特定的代码决定。\n\n### 版本号服务\n\n服务应尽量保持与旧客户端的后向兼容。 最终对应用的更改可能需要进行中断性变更。 中断旧客户端并强制其随服务一起更新不是一种好的用户体验。 若要在进行中断性变更的同时保持后向兼容性，一种方法是发布服务的多个版本。\n\ngRPC 支持可选的包说明符，它的功能非常类似于 .NET 命名空间。 实际上，如果 .proto 文件中未设置 option csharp_namespace，则 package 将用作生成的 .NET 类型的 .NET 命名空间。 该包可用于指定服务的版本号及其消息：\n\n```proto3\nsyntax = \"proto3\";\n\npackage greet.v1;\n\nservice Greeter {\n  rpc SayHello (HelloRequest) returns (HelloReply);\n}\n\nmessage HelloRequest {\n  string name = 1;\n}\n\nmessage HelloReply {\n  string message = 1;\n}\n```\n\n包名称与服务名称相结合以标识服务地址。 服务地址允许并行托管服务的多个版本：\n\n* greet.v1.Greeter\n* greet.v2.Greeter\n\n已进行版本控制的服务的实现在 Startup.cs 中注册：\n\n```c#\napp.UseEndpoints(endpoints =>\n{\n    // Implements greet.v1.Greeter\n    endpoints.MapGrpcService<GreeterServiceV1>();\n\n    // Implements greet.v2.Greeter\n    endpoints.MapGrpcService<GreeterServiceV2>();\n});\n```\n\n通过在包名称中包含版本号，你可发布具有中断性变更的服务 v2 版本，同时继续支持调用 v1 版本的旧客户端 。 更新客户端以使用 v2 服务后，你可选择删除旧版本。 计划发布服务的多个版本时：\n\n* 如果合理，请避免中断性变更。\n* 除非进行中断性更改，否则请勿更新版本号。\n* 进行中断性变更时，请务必更新版本号。\n\n发布多个服务版本会使其重复。 若要减少重复，请考虑将业务逻辑从服务实现移动到可由新旧实现重用的集中位置：\n```c#\nusing Greet.V1;\nusing Grpc.Core;\nusing System.Threading.Tasks;\n\nnamespace Services\n{\n    public class GreeterServiceV1 : Greeter.GreeterBase\n    {\n        private readonly IGreeter _greeter;\n        public GreeterServiceV1(IGreeter greeter)\n        {\n            _greeter = greeter;\n        }\n\n        public override Task<HelloReply> SayHello(HelloRequest request, ServerCallContext context)\n        {\n            return Task.FromResult(new HelloReply\n            {\n                Message = _greeter.GetHelloMessage(request.Name)\n            });\n        }\n    }\n}\n```\n\n使用不同包名称生成的服务和消息属于不同的 .NET 类型。 将业务逻辑移动到集中位置需要将消息映射到常见类型。\n\n### 原文地址\n\n* https://docs.microsoft.com/zh-cn/aspnet/core/grpc/versioning?view=aspnetcore-5.0","tags":["grpc"],"categories":["rpc"]},{"title":"redis分布式琐的正确姿势","url":"/2021/06/26/redis分布式琐的正确姿势/","content":"\n## redis锁使用的正确姿势\n\n可靠的分布式锁，要具备以下几个特性\n\n1. 互斥性。（在任意时刻，只有一个客户端能持有锁）\n2. 不会发生死锁。(即使有一个客户端在持有琐的期间崩溃而没有主动释放锁，也能保证后续其他客户端能加锁)\n3. 具有容错性。（只要大部分的Redis正常运行，客户端就可以加锁和解锁）\n<!-- more -->\n4. 解铃还需系铃人。（加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了）\n5. 锁不能自己失效。（正常执行过程中锁不能因为某些原因自己失效，会造成多个程序运行同一个任务）\n\n### 错误案例\n\n#### setNx\n\nSETNX key value\n\nredis> SETNX job \"programmer\"    # job 设置成功\n\n(integer) 1\n\n**条件分析**\n\n保证了redis里只有唯一的key存在\n\n有效时间避免了死锁的发生\n\n但不满足3，4，5特点。\n\n#### 采用Lua脚本实现\n\ngolang实现\n\n```golang\npackage redis\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"math/rand\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/go-kratos/kratos/v2/log\"\n\t\"github.com/go-redis/redis/v8\"\n)\n\nconst (\n\t_LockDistributedLua = \"local v;\" +\n\t\t\"v = redis.call('setnx',KEYS[1],ARGV[1]);\" +\n\t\t\"if tonumber(v) == 1 then\\n\" +\n\t\t\"    redis.call('expire',KEYS[1],ARGV[2])\\n\" +\n\t\t\"end\\n\" +\n\t\t\"return v\"\n\n\t_UnLockDistributedLua = \"if redis.call('get',KEYS[1]) == ARGV[1]\\n\" +\n\t\t\"then\\n\" +\n\t\t\"    return redis.call('del',KEYS[1])\\n\" +\n\t\t\"else\\n\" +\n\t\t\"    return 0\\n\" +\n\t\t\"end\"\n\n\t_DistributedTimeOut = 4\n\t_DistributedSuccess = 1\n)\n\nvar (\n\t_LockDistributedLuaScript   = redis.NewScript(_LockDistributedLua)\n\t_UnLockDistributedLuaScript = redis.NewScript(_UnLockDistributedLua)\n)\n\ntype Option struct {\n\tAddrs        []string\n\tPwd          string\n\tDB           int\n\tDialTimeout  time.Duration\n\tWriteTimeout time.Duration\n\tReadTimeout  time.Duration\n}\n\ntype Redis struct {\n\tcluster     *redis.ClusterClient\n\tsingle      *redis.Client\n\tclusterMode bool\n\tmutex       *sync.Mutex\n}\nfunc NewRedis(c *Option) *Redis {\n\tlog := log.NewHelper(log.DefaultLogger)\n\tif len(c.Addrs) == 0 {\n\t\treturn nil\n\t}\n\n\tr := &Redis{}\n\tr.log = log\n\tif len(c.Addrs) == 1 {\n\t\tr.single = redis.NewClient(\n\t\t\t&redis.Options{\n\t\t\t\tAddr:         c.Addrs[0], // use default Addr\n\t\t\t\tPassword:     c.Pwd,      // no password set\n\t\t\t\tDB:           c.DB,       // use default DB\n\t\t\t\tDialTimeout:  c.DialTimeout,\n\t\t\t\tReadTimeout:  c.ReadTimeout,\n\t\t\t\tWriteTimeout: c.WriteTimeout,\n\t\t\t})\n\t\tif err := r.single.Ping(context.Background()).Err(); err != nil {\n\t\t\tr.log.Errorf(err.Error())\n\t\t\treturn nil\n\t\t}\n\t\tr.single.Do(context.Background(), \"CONFIG\", \"SET\", \"notify-keyspace-events\", \"AKE\")\n\t\tr.clusterMode = false\n\t\tr.mutex = new(sync.Mutex)\n\t\treturn r\n\t}\n\n\tr.cluster = redis.NewClusterClient(\n\t\t&redis.ClusterOptions{\n\t\t\tAddrs:        c.Addrs,\n\t\t\tPassword:     c.Pwd,\n\t\t\tDialTimeout:  c.DialTimeout,\n\t\t\tReadTimeout:  c.ReadTimeout,\n\t\t\tWriteTimeout: c.WriteTimeout,\n\t\t})\n\tif err := r.cluster.Ping(context.Background()).Err(); err != nil {\n\t\tr.log.Errorf(\"cluster init failed, error : \", err.Error())\n\t}\n\tr.cluster.Do(context.Background(), \"CONFIG\", \"SET\", \"notify-keyspace-events\", \"AKE\")\n\tr.clusterMode = true\n\treturn r\n}\nfunc (r *Redis) Run(ctx context.Context, script *redis.Script, keys []string, argv ...interface{}) interface{} {\n\tr.mutex.Lock()\n\tdefer r.mutex.Unlock()\n\tif r.clusterMode {\n\t\treturn script.Run(ctx, r.cluster, keys, argv...).Val()\n\t}\n\treturn script.Run(ctx, r.single, keys, argv...).Val()\n}\n\nfunc (r *Redis) TryGetDistributedLock(ctx context.Context, key string) bool {\n\tvar res interface{}\n\tif r.clusterMode {\n\t\tres = _LockDistributedLuaScript.Run(ctx, r.cluster, []string{key}, \"_\", _DistributedTimeOut).Val()\n\t} else {\n\t\tres = _LockDistributedLuaScript.Run(ctx, r.single, []string{key}, \"_\", _DistributedTimeOut).Val()\n\t}\n\treturn res.(int64) == _DistributedSuccess\n}\n\nfunc (r *Redis) TryGetDistributedLockWithTimeOut(ctx context.Context, key string, duration time.Duration) bool {\n\tend := duration.Milliseconds()\n\tfor getNowMillisecond() <= end {\n\t\tsuc := r.TryGetDistributedLock(ctx, key)\n\t\tif suc {\n\t\t\treturn true\n\t\t}\n\t\tsleepMillisecond(80 + int64(rand.Int31n(30)))\n\t}\n\treturn false\n}\n\nfunc (r *Redis) ReleaseDistributedLock(ctx context.Context, key string) bool {\n\tr.mutex.Lock()\n\tdefer r.mutex.Unlock()\n\tvar res interface{}\n\tif r.clusterMode {\n\t\tres = _UnLockDistributedLuaScript.Run(ctx, r.cluster, []string{key}, \"_\").Val()\n\t} else {\n\t\tres = _UnLockDistributedLuaScript.Run(ctx, r.single, []string{key}, \"_\").Val()\n\t}\n\tif res.(int64) == _DistributedSuccess {\n\t\treturn true\n\t}\n\treturn false\n}\n```\n\n### 参考\n\n* https://www.bilibili.com/video/BV1r5411V7Sb","tags":["redis"],"categories":["redis"]},{"title":"cgroups隔离与限制","url":"/2021/06/21/cgroups隔离与限制/","content":"\n### cgroups介绍\n\ncgroups(Control Groups) 是linux 内核提供的一种为系统资源进程有效隔离和限制的一种手段。它可以有效的限制资源使用的cpu,内存及物理设备，如：磁盘等做精准限制。防止某一进程资源占用过大，导致整个系统物理资源耗尽，影响其他进程的运行。\n\n<!-- more -->\n\n### cgroups子系统\n\ncgroups为每种可以控制的资源定义了一个子系统。典型的子系统介绍如下：\n\n* cpu 子系统，主要限制进程的 cpu 使用率。\n* cpuacct 子系统，可以统计 cgroups 中的进程的 cpu 使用报告。\n* cpuset 子系统，可以为 cgroups 中的进程分配单独的 cpu 节点或者内存节点。\n* memory 子系统，可以限制进程的 memory 使用量。\n* blkio 子系统，可以限制进程的块设备 io。\n* devices 子系统，可以控制进程能够访问某些设备。\n* net_cls 子系统，可以标记 cgroups 中进程的网络数据包，然后可以使用 tc 模块（traffic control）对数据包进行控制。\n* freezer 子系统，可以挂起或者恢复 cgroups 中的进程。\nns 子系统，可以使不同 cgroups 下面的进程使用不同的 namespace。\n\n这里面每一个子系统都需要与内核的其他模块配合来完成资源的控制，比如对 cpu 资源的限制是通过进程调度模块根据 cpu 子系统的配置来完成的；对内存资源的限制则是内存模块根据 memory 子系统的配置来完成的，而对网络数据包的控制则需要 Traffic Control 子系统来配合完成。\n\n*cgroup* 将一组任务与一组参数相关联或更多子系统。\n\n*子系统*是一个利用任务分组的模块cgroups 提供的设施来处理任务组具体方式。一个子系统通常是一个“资源控制器”，它调度资源或应用每个 cgroup 限制，但它可能是任何想要对一组进程采取行动的东西，例如一种虚拟化子系统。\n\n一个 *hierarchy* 是一组排列在树中的 cgroups，使得系统中的每一个任务都在其中的一个 cgroup 中层次结构和一组子系统；每个子系统都有系统特定的状态附加到层次结构中的每个 cgroup。每个层次都有与之关联的 cgroup 虚拟文件系统的实例。\n\n### cgroups 层级结构（Hierarchy）\n\n内核使用 cgroup 结构体来表示一个 control group 对某一个或者某几个 cgroups 子系统的资源限制。cgroup 结构体可以组织成一颗树的形式，每一棵cgroup 结构体组成的树称之为一个 cgroups 层级结构。cgroups层级结构可以 attach 一个或者几个 cgroups 子系统，当前层级结构可以对其 attach 的 cgroups 子系统进行资源的限制。每一个 cgroups 子系统只能被 attach 到一个 cpu 层级结构中。\n\n<img src=\"/images/Istio/cgroups/cgroups.png\" art=\"cgroups\" width=\"500px\">\n\n比如上图表示两个cgroups层级结构，每一个层级结构中是一颗树形结构，树的每一个节点是一个 cgroup 结构体（比如cpu_cgrp, memory_cgrp)。第一个 cgroups 层级结构 attach 了 cpu 子系统和 cpuacct 子系统， 当前 cgroups 层级结构中的 cgroup 结构体就可以对 cpu 的资源进行限制，并且对进程的 cpu 使用情况进行统计。 第二个 cgroups 层级结构 attach 了 memory 子系统，当前 cgroups 层级结构中的 cgroup 结构体就可以对 memory 的资源进行限制。\n\n在每一个 cgroups 层级结构中，每一个节点（cgroup 结构体）可以设置对资源不同的限制权重。比如上图中 cgrp1 组中的进程可以使用60%的 cpu 时间片，而 cgrp2 组中的进程可以使用20%的 cpu 时间片。\n\n### 未使用cgroup限制后果\n\n**以下所有操作都是在虚拟机 centos8里面进行操作实验**\n\n我们在终端运行一下死循环，并top查看。\n\n```\n[root@localhost ~]# while : ; do : ;done\n[1] 10179\n```\n\n牢记该进程id，下面进行进程隔离是需要用到。也可通过ps查看。\n\n<img src=\"/images/Istio/cgroups/cgroups-unlimit.png\" art=\"cgroups\" width=\"500px\">\n\n此时cpu爆满，严重影响其他进程。\n\n我们如何将该进程进行有效的资源限制来保护我们系统上的其他资源呢？请看下面操作\n\n### linux 进程隔离\n\n```\n[root@localhost ~]# cd /sys/fs/cgroups/cpu\n[root@localhost cpu]# mkdir my-app\n```\n\n如图：\n\n<img src=\"/images/Istio/cgroups/shell-loop.png\" art=\"cgroups\" width=\"500px\">\n\n查看我们新建的my-app 控制组限制：\n```\n[root@localhost cpu]# cat /sys/fs/cgroup/cpu/container/cpu.cfs_quota_us \n-1\n[root@localhost cpu]# cat /sys/fs/cgroup/cpu/container/cpu.cfs_period_us \n100000\n```\n\nmy-app 控制组里的 CPU quota 还没有任何限制（即：-1），CPU period 则是默认的 100 ms（100000 us）。\n\n接下来，我们可以通过修改这些文件的内容来设置限制。比如，向 my-app 组里的 cfs_quota 文件写入 20 ms（20000 us）：\n\n```\n[root@localhost cpu]# echo 20000 > /sys/fs/cgroup/cpu/my-app/cpu.cfs_quota_us\n```\n\n它意味着在每 100 ms 的时间里，被该控制组限制的进程只能使用 20 ms 的 CPU 时间，也就是说这个进程只能使用到 20% 的 CPU 带宽。\n\n接下来，我们把被限制的进程的 PID 写入 my-app 组里的 tasks 文件，上面的设置就会对该进程生效了：\n\n```\n[root@localhost cpu]# echo 10179 > /sys/fs/cgroup/cpu/my-app/tasks \n```\n\n此时我们在通过top 指令查看资源消耗：\n\n<img src=\"/images/Istio/cgroups/shell-cgroups.png\" art=\"cgroups\" width=\"500px\">\n\n### docker 容器中的隔离使用\n\n```\ndocker run -it --cpu-period=100000 --cpu-quota=20000 ubuntu bin/bash\n```\n* --cpu-period cpu运行时间\n* --cpu-quota 分配到到cpu运行时间\n\n上面到示例意味者 运行 100ms，只能分配实际运行时间为 20ms,也就意味只占总cpu的20%。\n\n\n运行容器之后，在交互洁面输入下面代码测试：\n```\n[root@localhost ~]# while : ; do : ;done\n```\n\n此时查看top命令，cpu 只占到了 20%,达到了有效的限制。\n\n<img src=\"/images/Istio/cgroups/cgroup-limit.png\" art=\"cgroups\" width=\"500px\">\n\n\n\n\n### 删除限制组\n\n```\nrmdir my-app\n```\n\n### 未完待续\n\n参考：\n\n* https://www.kernel.org/doc/Documentation/cgroup-v1/cgroups.txt\n* https://www.cnblogs.com/sammyliu/p/5886833.html\n* https://tech.meituan.com/2015/03/31/cgroups.html\n\n\n","tags":["linux","container"],"categories":["Istio"]},{"title":"leetcode-2079.LRU缓存","url":"/2021/06/15/leetcode-2079.LRU缓存/","content":"\n**题目**\n\n设计和构建一个“最近最少使用”缓存，该缓存会删除最近最少使用的项目。缓存应该从键映射到值(允许你插入和检索特定键对应的值)，并在初始化时指定最大容量。当缓存被填满时，它应该删除最近最少使用的项目。\n\n它应该支持以下操作： 获取数据 get 和 写入数据 put 。\n\n<!-- more -->\n\n获取数据 get(key) - 如果密钥 (key) 存在于缓存中，则获取密钥的值（总是正数），否则返回 -1。\n写入数据 put(key, value) - 如果密钥不存在，则写入其数据值。当缓存容量达到上限时，它应该在写入新数据之前删除最近最少使用的数据值，从而为新的数据值留出空间。\n\n**示例:**\n\n```\nLRUCache cache = new LRUCache( 2 /* 缓存容量 */ );\n\ncache.put(1, 1);\ncache.put(2, 2);\ncache.get(1);       // 返回  1\ncache.put(3, 3);    // 该操作会使得密钥 2 作废\ncache.get(2);       // 返回 -1 (未找到)\ncache.put(4, 4);    // 该操作会使得密钥 1 作废\ncache.get(1);       // 返回 -1 (未找到)\ncache.get(3);       // 返回  3\ncache.get(4);       // 返回  4\n```\n\ngolang 题解：\n\n通过内置 container/list包 双向链表实现：\n\n```\npackage lru\n\nimport \"container/list\"\n\ntype LRUCache struct {\n\tCap int\n\tKeys map[int]*list.Element\n\tList *list.List\n\n}\n\ntype Pairs struct {\n\tK, V int\n}\n\nfunc Constructor(capacity int) LRUCache {\n\treturn LRUCache{\n\t\tCap:  capacity,\n\t\tKeys: make(map[int]*list.Element),\n\t\tList: list.New(),\n\t}\n}\n\nfunc (this *LRUCache) Get(key int) int {\n\tif el , ok := this.Keys[key]; ok {\n\t\tthis.List.MoveToFront(el)\n\t\treturn el.Value.(Pairs).V\n\t}\n\treturn -1\n}\n\n\nfunc (this *LRUCache) Put(key int, value int)  {\n\tif el, ok := this.Keys[key]; ok {\n\t\tel.Value = Pairs{\n\t\t\tK: key,\n\t\t\tV: value,\n\t\t}\n\t\tthis.List.PushFront(el)\n\t} else {\n\t\tel = this.List.PushFront(Pairs{\n\t\t\tK: key,\n\t\t\tV: value,\n\t\t})\n\t\tthis.Keys[key] = el\n\t}\n\tif this.List.Len() > this.Cap {\n\t\tel := this.List.Back()\n\t\tthis.List.Remove(el)\n\t\tdelete(this.Keys, el.Value.(Pairs).K)\n\t}\n}\n```\n\n\n来源：力扣（LeetCode）\n\n链接：https://leetcode-cn.com/problems/lru-cache-lcci","tags":["algorithm"],"categories":["golang"]},{"title":"vscode搭建golang开发环境","url":"/2021/06/10/vscode搭建golang开发环境/","content":"\n在 vscode 的使用过程中,自己也是从小白到慢慢熟练vscode的日常开发，现在已经很少使用goland 等IDE，平时基本都在使用vscode。本篇文章主要记录自己vscode等一些探索，方便大家快速使用vscode做golang 开发。\n\n## golang 插件安装\n\n<!-- more -->\n\n首先需要安装golang 相关插件包，Mac 环境下 按快捷键 command+shift+p（windows 环境下 ctrl+shift+p）打开控制面板，输入 \"GO: Install/Update\" 选中 \"GO: Install/Update Tools\" 点击进入，全选，点击ok 自动安装。主意此方法部分包需要科学上网，否则会出现安装失败问题。\n\n**vscode 配置科学上网 proxy**\n\n进入设置（Settings），搜索 \"Http: Proxy\"，配置代理即可。\n\n如果无法科学上网，安装失败，可更改go mod 走国内代理即可，详细方法，可参照此文：https://blog.csdn.net/qq_41065919/article/details/107710144\n\n## code-runner 运行项目\n\nCode Runner支持了 Node.js, Python, C++, Java, PHP, Perl, Ruby, Go等超过40种的语言。下面，我们就来看看如何来玩转Code Runner，提高你的效率。\n\n首先需要安装**code-runner**插件，在插件库搜索 code-runner，并安装。\n\n**运行golang的几种情况**\n\n### 单文件运行和无需指定配置文件项目\n\n直接找到main文件所在目录，点击main文件，无需任何配置，直接点击vscode右上角运行按钮即可直接运行。\n\n### 运行需要指定配置的项目\n\n需要在项目目录下添加.vscode的文件夹，并添加settings.json配置文件，添加配置信息如下所示：\n\n#### 相对路径配置\n\n```\n{\n    \"code-runner.executorMap\": {\n        \"go\": \"cd  $dir && go run . -conf ../../configs\",\n    }\n}\n```\n\n可指定如上配置：$dir 为系统变量，当打开main文件之后，点击运行按钮时，vscode 会自动进入main 文件所在目录，并根据 -conf 指定的配置文件，启动项目。\n\n此方式也适合多项目启动，如果我们工作区下面有多个项目，每个服务都需要启动，这种方式也比较方便，只是每次启动服务时，都需要打开相应的main文件。\n\n这种相对路径的配置方法每次启动都需要打开相应的main文件，多次一举，也会很不方便，下面的绝对目录方式就可以完美解决。单不适合多服务都需要启动模式。\n\n#### 绝对路径配置\n\n```\n{\n    \"code-runner.executorMap\": {\n        \"go\": \"cd  /Users/limuzi/go/src/{grogram}/cmd/graphql-layout && go run . -conf ../../configs\",\n    },\n    \"code-runner.fileDirectoryAsCwd\": true\n}\n```\ngrogram 替换成自己真实项目名称即可。此种方式比较简单，在打开任意go文件时，都可直接点击右上角运行按钮，即可启动程序运行。\n\n## debug\n\n### 单main文件\n\n可直接点击 Run and Debug 按钮，开启调试\n\n**停止运行：**\n\n* 控制面板：输入 Stop Code Run 点击即可\n* 快捷键 ctrl+option+M 停止运行\n\n### 调试项目\n\n首先需要安装 div依赖包\n\n安装方式：\n\n```\ngo get -u github.com/go-delve/delve/cmd/dlv\n```\n\n调试项目是，需要在项目目录.vscode文件夹下，添加launch.json 配置。\n\n```\n{\n    // Use IntelliSense to learn about possible attributes.\n    // Hover to view descriptions of existing attributes.\n    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387\n    \"version\": \"0.2.0\",\n    \"configurations\": [\n        {\n            \"name\": \"debug order\",\n            \"type\": \"go\",\n            \"request\": \"launch\",\n            \"mode\": \"debug\",\n            \"program\": \"${workspaceFolder}/app/order/cmd/server\",\n            \"cwd\": \".\",\n            \"args\": [\"-conf\", \"${workspaceFolder}/app/order/configs/config.yaml\"],\n            \"env\": {\n                \"RUN_ENV\":\"dev\"\n            },\n            \"dlvLoadConfig\": {\n                \"followPointers\": true,\n                \"maxVariableRecurse\": 1,\n                \"maxStringLen\": 5000,\n                \"maxArrayValues\": 64,\n                \"maxStructFields\": -1\n            }\n        },\n        {\n            \"name\": \"debug admin\",\n            \"type\": \"go\",\n            \"request\": \"launch\",\n            \"mode\": \"debug\",\n            \"program\": \"${workspaceFolder}/app/admin/cmd/server\",\n            \"cwd\": \".\",\n            \"args\": [\"-conf\", \"${workspaceFolder}/app/admin/configs/config.yaml\"],\n            \"env\": {\n                \"RUN_ENV\":\"dev\"\n            },\n            \"dlvLoadConfig\": {\n                \"followPointers\": true,\n                \"maxVariableRecurse\": 1,\n                \"maxStringLen\": 5000,\n                \"maxArrayValues\": 64,\n                \"maxStructFields\": -1\n            }\n        }\n    ]\n}\n```\n\n* ${workspaceFolder}: 工作区根目录\n\n相关属性介绍：\n\n* name: 调试界面下拉选择项的名称\n* type: 设置为go无需改动，是 vscode 用于计算调试代码需要用哪个扩展\n* mode: 可以设置为 auto, debug, remote, test, exec 中的一个\n* program: 调试程序的路径（绝对路径）\n* env: 调试时使用的环境变量。例如:{ \"ENVNAME\": \"ENVVALUE\" }\n* envFile: 包含环境变量文件的绝对路径，在 env 中设置的属性会覆盖 envFile 中的配置\n* args: 传给正在调试程序命令行参数数组 可指定配置文件 如：[\"-conf\", \"${workspaceFolder}/app/admin/configs/config.yaml\"]\n* showLog: 布尔值，是否将调试信息输出\n* logOutput: 配置调试输出的组件（debugger, gdbwire, lldbout, debuglineerr, rpc）,使用,分隔， showLog 设置为 true 时，此项配置生效\n* buildFlags: 构建 go 程序时传给 go 编译器的标志\n* remotePath: 远程调试程序的绝对路径，当 mode 设置为 remote 时有效\n* dlvLoadConfig: 调试打印信息过长无法显示全部时，可添加此配置\n\ndlvLoadConfig 相关说明\n\n* maxStringLen: 显示的字符串最大长度\n\n## 提高开发效率的小方法：\n\n### 变量命名方式转换\n\n安装 Change-case插件\n\n打开控制面板, 输入change 即可快速将变量转换为选择类型：\n\n* Change Case snake: 转换为下划线类型\n* Change Case camel: 转换为驼峰命名\n....\n\n也可以选择 Change Case Commands 来选择需要的类型。\n\n### struct 快速填充\n\nmac 环境下 command+. 快速填充struct\n\n### struct 快速添加tag\n\nmac 环境下 command+shift+p 打开控制面板，输入 Add Tags,选择 Add Tags To Struct Fields()\n\n### struct 快速删除tag\n\nmac 环境下 command+shift+p 打开控制面板，输入 Remove Tag,选择 remove Tags From Struct Fields\n\n### 自动生成单元测试\n\nmac 环境下 command+shift+p 打开控制面板，输入 Generate Unit Tests,选择 Generate Unit Tests For File;即可自动为打开的文件生成单元测试。\n\n### 快速实现接口实现\n\n* impl 命令\n\n使用方法：\n\n进入到类型实现所在目录\n\n```\nimpl 'r *queryResolver' generated.QueryResolver\n```\n\n* r 为类型接收到形参\n* queryResolver 为类型名\n* generated.QueryResolver 接口 interface, generated 为包名，QueryResolver 为 interface 名称\n\n方法会自动生成到终端：\n\n```\nfunc (r *queryResolver) GetOrder(ctx context.Context, id int) (*common.OrderInfo, error) {\n        panic(\"not implemented\") // TODO: Implement\n}\n\nfunc (r *queryResolver) GetAddress(ctx context.Context, id int) (*common.AddressInfo, error) {\n        panic(\"not implemented\") // TODO: Implement\n}\n```\n\n## 好用的插件\n\n个人在使用过程中总结了以下好用的插件：\n\n* Change-case 变量命名格式转换\n* Remote-ssh ssh客户端\n* Gitlens\n* Git Graph\n* Git History\n* Todo Tree\n* Docker\n* Live Share 很好的一个团队协作工具\n* MySQL cweijan.vscode-mysql-client2 好用的数据库客户端\n* CodeStream: GitHub, GitLab, Bitbucket PRs and Code Review 协作工具\n","tags":["golang","vscode"],"categories":["golang"]},{"title":"grpc 内置protobuf类型使用","url":"/2021/06/08/grpc内置protobuf类型使用/","content":"\n介绍内置protobuf 类型使用过程中，使用 B站开源框架 kratos 作为示例demo,kratos 框架会同时生成http代码及rpc代码，方便演示。[kratos详细了解](https://github.com/go-kratos/kratos)\n\n使用protocal buffers 定义传参类型时，经常会遇到复杂场景及一些特殊情况需要定义proto文件的message，本文介绍protocal buffers内置数据类型的使用场景及使用示例。由于个人水平有限，如有不当之处还请指正。\n\n## 空请求 empty 类型\n\n适用无传参或返回的message 类型，但通常不建议使用，为了更好的向后兼容，通常定义一个空的message。\n\n<!-- more -->\n\n**proto定义**\n\n需要导入 google/protobuf/empty.proto 包。\n```\nimport \"google/protobuf/empty.proto\";\n\nrpc SayEmpty (google.protobuf.Empty) returns (HelloReply)  {\n    option (google.api.http) = {\n      get: \"/helloworld/{name}\"\n    };\n  }\n```\n\n**service 层使用方法，则需要导入 emptypb 包**\n\n```\nimport \"google.golang.org/protobuf/types/known/emptypb\"\n\n....省略其他代码\n\nfunc (s *GreeterService) SayEmpty(ctx context.Context, _ *emptypb.Empty)  (*v1.HelloReply, error) {\n\treturn &v1.HelloReply{Message: \"Hello empty\"}, nil\n}\n```\n\n空message表示，无传参或返回具体数据，但为了更好的兼容，通常不建议这样做。\n\n## wrappers 类型\n\n用于区分参数为空及默认值场景。\n\nprotocal buffers  定义的message 中，参数值默认为类型的默认值，即：bool 类型默认为 false, int32，int64 默认为 0，string 默认为空字符串等等。\n\n如何区分本身是默认值还是传参数为空呢？这里就需要用到wrappers包的相关类型。\n\n**proto 定义：**\n\n```\nimport \"google/protobuf/wrappers.proto\";\n\n....省略其他代码\n\nmessage HelloIsDefaultRequest {\n  string name = 1;\n  google.protobuf.Int32Value age = 2;\n}\n```\n\n**service 使用：**\n\n可通过值是否为 nil 来判断是否为默认值还是传参为类型的0值。\n\n```\nfunc (s *GreeterService) IsDefault(ctx context.Context, in *v1.HelloIsDefaultRequest) (*v1.HelloDefaultReply, error)  {\n\tvar age int32 = 18\n\tif in.GetAge() != nil {\n\t\tage = in.GetAge().GetValue()\n\t}\n\treturn &v1.HelloDefaultReply{\n\t\tName: in.GetName(),\n\t\tAge:  age,\n\t}, nil\n}\n```\n\nwrappers包下可包装的类型有多个，有： Int32Value， Int64Value， BoolValue， ListValue， NullValue， StringValue， BytesValue等多种类型，具体了解，可查看代码。\n\n## FieldMask 类型\n\n个人在使用过程中，主要用于更新方法，通过传参FieldMask 来控制更新字段\n\n**proto定义**\n\n```\nimport \"google/protobuf/field_mask.proto\";\n\n....省略其他代码\n\nrpc FiledMask (HelloFieldMaskRequest) returns (HelloFieldMaskResponse)  {\n    option (google.api.http) = {\n      post: \"/hello/fieldMask\"\n    };\n}\n\n....省略其他代码\n\nmessage HelloFieldMaskRequest {\n  int32 task_id = 1;\n  bool is_delete = 2;\n  bool is_finished = 3;\n  google.protobuf.FieldMask field_mask = 4;\n}\n\nmessage HelloFieldMaskResponse {\n  repeated string field_mask = 1;\n}\n```\n\n**service 接收示例：**\n\n```\nfunc (s *GreeterService) FiledMask(ctx context.Context, in *v1.HelloFieldMaskRequest) (*v1.HelloFieldMaskResponse, error)  {\n\ts.log.Infof(\"task_id = %+v\", in.GetTaskId())\n\ts.log.Infof(\"is_finished = %+v\", in.GetIsFinished())\n\ts.log.Infof(\"is_deleted = %+v\", in.GetIsDelete())\n\treturn &v1.HelloFieldMaskResponse{\n\t\tFieldMask: in.GetFieldMask().Paths,\n\t}, nil\n}\n```\n\n此时接收到到FieldMask 字段为slice 类型，可判断字段是否在slice 里做响应逻辑处理。\n\n请求示例：\n\n```\ncurl -X POST -H \"Content-Type:application/json\" -d '{\"task_id\":1, \"is_finished\":true,\"field_mask\":\"isFinished\"}' 127.0.0.1:8000/hello/fieldMask\n```\n\n注意 传参为camelCase 类型，即 生成到pb文件里，tag为 protobuf json定义：isFinished, isDelete。\n\n如：\n```\ntype HelloFieldMaskRequest struct {\n\tstate         protoimpl.MessageState\n\tsizeCache     protoimpl.SizeCache\n\tunknownFields protoimpl.UnknownFields\n\n\tTaskId     int32                  `protobuf:\"varint,1,opt,name=task_id,json=taskId,proto3\" json:\"task_id,omitempty\"`\n\tIsDelete   bool                   `protobuf:\"varint,2,opt,name=is_delete,json=isDelete,proto3\" json:\"is_delete,omitempty\"`\n\tIsFinished bool                   `protobuf:\"varint,3,opt,name=is_finished,json=isFinished,proto3\" json:\"is_finished,omitempty\"`\n\tFieldMask  *fieldmaskpb.FieldMask `protobuf:\"bytes,4,opt,name=field_mask,json=fieldMask,proto3\" json:\"field_mask,omitempty\"`\n}\n```\n\n另外如果field_mask传递多个字段，此时需要用“,” 分割：\n\n如：\n\n```\ncurl -X POST -H \"Content-Type:application/json\" -d '{\"task_id\":1, \"is_finished\":true,\"field_mask\":\"isFinished, isDelete\"}' 127.0.0.1:8000/hello/fieldMask\n```\n\n## Any 类型\n\n**官方定义：**\n> The Any message type lets you use messages as embedded types without having their .proto definition. An Any contains an arbitrary serialized message as bytes, along with a URL that acts as a globally unique identifier for and resolves to that message's type. To use the Any type, you need to import google/protobuf/any.proto.\n\nAny 消息类型允许您将消息用作嵌入类型，而无需它们的 .proto 定义。 Any 包含作为字节的任意序列化消息，以及充当全局唯一标识符并解析为该消息类型的 URL。 要使用 Any 类型，您需要导入 google/protobuf/any.proto。\n\n如：\n```\nimport \"google/protobuf/any.proto\";\n\nmessage ErrorStatus {\n  string message = 1;\n  repeated google.protobuf.Any details = 2;\n}\n```\n\n给定消息类型的 URL 定义格式为：\n```\ntype.googleapis.com/_packagename_._messagename_.\n```\n\n使用示例：\n\n**proto 定义**\n\n```\nsyntax = \"proto3\";\n\npackage helloworld.v1;\n\nimport \"google/protobuf/any.proto\";\n\n....省略其他代码\n\nrpc AnyTypes (HelloAnyTypesRequest) returns (HelloAnyTypesResponse)  {\n    option (google.api.http) = {\n      post: \"/hello/any\"\n    };\n}\n\n....省略其他代码\n\nmessage HelloAnyTypesRequest {\n  string topic = 1;\n  google.protobuf.Any desc = 2;\n}\n\nmessage DescType {\n  string value = 1;\n}\n\nmessage HelloAnyTypesResponse {\n  string topic = 1;\n  string desc = 2;\n}\n\n```\n\n**service 使用示例：**\n\n```\nfunc (s *GreeterService) AnyTypes(ctx context.Context, in *v1.HelloAnyTypesRequest) (*v1.HelloAnyTypesResponse, error)  {\n\ts.log.Infof(\"topic = %+v\", in.GetTopic())\n\ts.log.Infof(\"desc = %s\", in.GetDesc().GetValue())\n\treturn &v1.HelloAnyTypesResponse{\n\t\tTopic: in.GetTopic(),\n\t\tDesc: string(in.GetDesc().GetValue()),\n\t}, nil\n}\n```\n\n\n请求示例：\n```\ncurl -X POST -H \"Content-Type:application/json\" -d '{\"topic\":\"this is any type\", \"desc\":{\"@type\":\"type.googleapis.com/helloworld.v1.DescType\", \"value\":\"this is any type desc\"}}' 127.0.0.1:8000/hello/any\n```\n\n* @type 为 type.googleapis.com/ + package_name + message_name\n* value 为message 的字段定义\n\n\n## Timestamp 类型\n\n传递 ISO 时间对象，接收到之后，通过proto可以任意 转换时间对象方便处理：\n\n**proto 定义：**\n\n```\nsyntax = \"proto3\";\n\n....省略其他代码\n\nrpc Times (HelloTsRequest) returns (HelloTsResponse)  {\n    option (google.api.http) = {\n      post: \"/hello/ts\"\n    };\n}\n\n....省略其他代码\n\nmessage HelloTsRequest {\n  google.protobuf.Timestamp time_begin = 1;\n}\n\nmessage HelloTsResponse {\n  int64 timestamp = 1;\n}\n```\n\n**service 使用示例：**\n\n```\nfunc (s *GreeterService) Times(ctx context.Context, in *v1.HelloTsRequest) (*v1.HelloTsResponse, error)  {\n\ts.log.Infof(\"seconds = %+v\", in.GetTimeBegin().GetSeconds())\n\ts.log.Infof(\"nano = %s\", in.GetTimeBegin().GetNanos())\n\treturn &v1.HelloTsResponse{Timestamp: in.GetTimeBegin().GetSeconds()},nil\n}\n```\n\n调用示例：\n\n```\ncurl -X POST -H \"Content-Type:application/json\" -d '{\"time_begin\":\"2021-06-08T15:15:30.069Z\"}' 127.0.0.1:8000/hello/ts\n```\n\n注意传递的时间对象为UTC标准时间，否则转化获取到的时间戳不正确。\n\n[javascript demo](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date/toISOString)\n\n\n## Struct 类型\n\n**官方描述**\n\n> Any JSON object\n\n任意 json 类型，当我们传递不固定的json数据时，此时无法对应到某个具体到proto message, struct类型就大显神通了。\n\n下面来看看具体到使用：\n\n**proto文件到定义：**\n\n需要导入 struct包：\n\n```\nsyntax = \"proto3\";\n\npackage helloworld.v1;\n\nimport \"google/protobuf/struct.proto\";\n\n....省略其他代码\n\nrpc AnyJson (HelloStructRequest) returns (HelloStructResponse)  {\n    option (google.api.http) = {\n      post: \"/hello/struct\"\n    };\n}\n\n....省略其他代码\n\nmessage HelloStructRequest {\n  google.protobuf.Struct json = 1;\n}\n\nmessage HelloStructResponse {\n  string detail = 2;\n}\n```\n\n**service 业务代码处理**\n\n```\nfunc (s *GreeterService) AnyJson(ctx context.Context, in *v1.HelloStructRequest) (*v1.HelloStructResponse, error)  {\n\tmaps := in.GetJson().AsMap()\n\ts.log.Infof(\"this is map[string]interface{}  = %+v\", maps)\n\tfor key, value := range in.GetJson().GetFields() {\n\t\ts.log.Infof(\"maps key = %+v\", key)\n\t\tswitch value.Kind.(type) {\n\t\tcase *structpb.Value_NumberValue:\n\t\t\ts.log.Infof(\"maps value is number = %+v\", value.GetNumberValue())\n\t\tcase *structpb.Value_StringValue:\n\t\t\ts.log.Infof(\"maps value is number = %+v\", value.GetStringValue())\n\t\tcase *structpb.Value_BoolValue:\n\t\t\ts.log.Infof(\"maps value is number = %+v\", value.GetBoolValue())\n\t\tdefault:\n\t\t\ts.log.Infof(\"maps value is other type = %+v\", value.AsInterface())\n\t\t}\n\t}\n\tbts, _ := json.Marshal(maps)\n\treturn &v1.HelloStructResponse{\n\t\tDetail: string(bts),\n\t},nil\n}\n```\n\n值的类型，可通过 structpb 包下定义的枚举类型来判断：structpb.Value_StringValue，Value_NumberValue， Value_BoolValue， structpb.Value_ListValue， structpb.Value_StructValue， structpb.Value_NullValue等等，具体枚举值，可查看structpb包源码。\n\n\n## 代码地址\n\nhttps://github.com/luckylsx/kratos-proto-demo\n\n## 参考\n\n* https://developers.google.com/protocol-buffers/docs/proto3","tags":["grpc","kratos","Protocal Buffers"],"categories":["rpc"]},{"title":"透视http协议(1)","url":"/2021/06/05/透视http协议(1)/","content":"\n## HTTP的前世今生\n\nHTTP 协议是怎么来的？它最开始是什么样子的？又是如何一步一步发展到今天，几乎“统治”了整个互联网世界的呢？\n\n### 史前时期\n\n20 世纪 60 年代，美国国防部高等研究计划署（ARPA）建立了 ARPA 网，它有四个分布在各地的节点，被认为是如今互联网的“始祖”。\n\n<!-- more -->\n\n### 创世纪\n\n1989 年，任职于欧洲核子研究中心（CERN）的蒂姆·伯纳斯 - 李（Tim Berners-Lee）发表了一篇论文，提出了在互联网上构建超链接文档系统的构想。这篇论文中他确立了三项关键技术。\n\n1. URI：即统一资源标识符，作为互联网上资源的唯一身份；\n2. HTML：即超文本标记语言，描述超文本文档；\n3. HTTP：即超文本传输协议，用来传输超文本。\n\n基于它们，就可以把超文本系统完美地运行在互联网上，让各地的人们能够自由地共享信息，蒂姆把这个系统称为“万维网”（World Wide Web），也就是我们现在所熟知的 Web。\n\n### HTTP/0.9\n\n20 世纪 90 年代初期的互联网世界非常简陋，计算机处理能力低，存储容量小，网速很慢，还是一片“信息荒漠”。网络上绝大多数的资源都是纯文本，很多通信协议也都使用纯文本，所以 HTTP 的设计也不可避免地受到了时代的限制。\n\n这一时期的 HTTP 被定义为 0.9 版，结构比较简单，为了便于服务器和客户端处理，它也采用了纯文本格式。所以只允许用“GET”动作从服务器上获取 HTML 文档，并且在响应请求之后立即关闭连接，功能非常有限。\n\n### HTTP/1.0\n\n1993 年，NCSA（美国国家超级计算应用中心）开发出了 Mosaic，是第一个可以图文混排的浏览器，随后又在 1995 年开发出了服务器软件 Apache，简化了 HTTP 服务器的搭建工作。\n\n同一时期，计算机多媒体技术也有了新的发展：1992 年发明了 JPEG 图像格式，1995 年发明了 MP3 音乐格式。\n\n更的多的人开始使用互联网,促进了 HTTP 的发展。于是在这些已有实践的基础上，经过一系列的草案，HTTP/1.0 版本在 1996 年正式发布。它在多方面增强了 0.9 版，形式上已经和我们现在的 HTTP 差别不大了，例如：\n\n1. 增加了 HEAD、POST 等新方法；\n2. 增加了响应状态码，标记可能的错误原因；\n3. 引入了协议版本号概念；\n4. 引入了 HTTP Header（头部）的概念，让 HTTP 处理请求和响应更加灵活；\n5. 传输的数据不再仅限于文本。\n\n### HTTP/1.1\n\n1999 年，HTTP/1.1 发布了 RFC 文档,编号为 2616。HTTP/1.1 是对 HTTP/1.0 的小幅度修正，它是一个“正式的标准”，而不是一份可有可无的“参考文档”。意味着今后互联网上所有的浏览器、服务器、网关、代理等等，只要用到 HTTP 协议，就必须严格遵守这个标准，相当于是互联网世界的一个“立法”。\n\nHTTP/1.1 主要的变更点有：\n\n1. 增加了 PUT、DELETE 等新的方法；\n2. 增加了缓存管理和控制；明确了连接管理，允许持久连接；\n3. 允许响应数据分块（chunked），利于传输大文件；\n4. 强制要求 Host 头，让互联网主机托管成为可能。\n\n### HTTP/2\n\nGoogle 首先开发了自己的浏览器 Chrome，然后推出了新的 SPDY 协议，互联网标准化组织以 SPDY 为基础开始制定新版本的 HTTP 协议，最终在 2015 年发布了 HTTP/2，RFC 编号 7540。\n\nHTTP/2 的制定充分考虑了现今互联网的现状：宽带、移动、不安全，在高度兼容 HTTP/1.1 的同时在性能改善方面做了很大努力，主要的特点有：\n\n1. 二进制协议，不再是纯文本；\n2. 可发起多个请求，废弃了 1.1 里的管道；\n3. 使用专用算法压缩头部，减少数据传输量；\n4. 允许服务器主动向客户端推送数据；增强了安全性，“事实上”要求加密通信。\n\n### HTTP/3\n\nGoogle 发明的另一个个新的协议 QUIC （Quick UDP Internet Connection）,2018 年，互联网标准化组织 IETF 提议将“HTTP over QUIC”更名为“HTTP/3”并获得批准，HTTP/3 正式进入了标准化制订阶段。\n\n### 小结\n\n1. HTTP 协议始于三十年前蒂姆·伯纳斯 - 李的一篇论文；\n2. HTTP/0.9 是个简单的文本协议，只能获取文本资源；\n3. HTTP/1.0 确立了大部分现在使用的技术，但它不是正式标准；\n4. HTTP/1.1 是目前互联网上使用最广泛的协议，功能也非常完善；\n5. HTTP/2 基于 Google 的 SPDY 协议，注重性能改善，但还未普及；\n6. HTTP/3 基于 Google 的 QUIC 协议，是将来的发展方向。\n\n##  HTTP是什么？HTTP又不是什么？\n\nHTTP 就是超文本传输协议，也就是 HyperText Transfer Protocol。\n\n### HTTP 是什么\n\n“超文本传输协议”，分别是：“超文本”“传输”和“协议”\n\n**HTTP 是一个协议**\n\nHTTP 是一个用在计算机世界里的协议。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范，以及相关的各种控制和错误处理方式。\n\n**HTTP 是一个“传输协议”**\n\nHTTP 是一个在计算机世界里专门用来在两点之间传输数据的约定和规范。\n\n**超文本**\n\n所谓“超文本”，就是“超越了普通文本的文本”，它是文字、图片、音频和视频等的混合体，最关键的是含有“超链接”，能够从一个“超文本”跳跃到另一个“超文本”，形成复杂的非线性、网状的结构关系。\n\n**HTTP（超文本传输协议）的定义**\nHTTP 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范。\n\n### HTTP 不是什么？\n\nHTTP 是一个协议，不存在“单独的实体”。它不是浏览器、手机 APP 那样的应用程序，也不是 Windows、Linux 那样的操作系统，更不是 Apache、Nginx、Tomcat 那样的 Web 服务器。\n\n* HTTP 不是互联网。\n* HTTP 不是编程语言\n* HTTP 不是 HTML\n* HTTP 不是一个孤立的协议\n\n在互联网世界里，HTTP 通常跑在 TCP/IP 协议栈之上，依靠 IP 协议实现寻址和路由、TCP 协议实现可靠数据传输、DNS 协议实现域名查找、SSL/TLS 协议实现安全通信。此外，还有一些协议依赖于 HTTP，例如 WebSocket、HTTPDNS 等。这些协议相互交织，构成了一个协议网，而 HTTP 则处于中心地位。\n\n### 小结\n\n* HTTP 是一个用在计算机世界里的协议，它确立了一种计算机之间交流通信的规范，以及相关的各种控制和错误处理方式。\n* HTTP 专门用来在两点之间传输数据，不能用于广播、寻址或路由。\n* HTTP 传输的是文字、图片、音频、视频等超文本数据。\n* HTTP 是构建互联网的重要基础技术，它没有实体，依赖许多其他的技术来实现，但同时许多技术也都依赖于它。\n\n## HTTP世界全览 - 上\n\n介绍HTTP 相关的各种概念和角色，清楚它们在链路中的位置和作用，以及发起一个 HTTP 请求会有哪些角色参与，会如何影响请求的处理。\n\n### 网络世界\n\n互联网的正式名称是 Internet，里面存储着无穷无尽的信息资源，我们通常所说的“上网”实际上访问的只是互联网的一个子集“万维网”（World Wide Web），它基于 HTTP 协议，传输 HTML 等超文本资源，能力也就被限制在 HTTP 协议之内。\n\n互联网上还有许多万维网之外的资源，例如常用的电子邮件、BT 和 Magnet 点对点下载、FTP 文件下载、SSH 安全登录、各种即时通信服务等等，它们需要用各自的专有协议来访问。\n\n### 浏览器\n\n上网就要用到浏览器，常见的浏览器有 Google 的 Chrome、Mozilla 的 Firefox、Apple 的 Safari、Microsoft 的 IE 和 Edge，浏览器的正式名字叫“Web Browser”，就是检索、查看互联网上网页资源的应用程序，名字里的 Web，实际上指的就是“World Wide Web”，也就是万维网。\n\n浏览器本质上是一个 HTTP 协议中的请求方，使用 HTTP 协议获取网络上的各种资源。例如，HTML 排版引擎用来展示页面，JavaScript 引擎用来实现动态化效果，还有开发者工具用来调试网页。\n\n在 HTTP 协议里，浏览器的角色被称为“User Agent”即“用户代理”，意思是作为访问者的“代理”来发起 HTTP 请求。通常都简单地称之为“客户端”。\n\n### Web 服务器\n\n协议另一端的应答方（响应方）就是服务器，Web Server。\n\nWeb 服务器 有两个层面的含义：硬件和软件。\n\n**硬件**含义就是物理形式或“云”形式的机器，在大多数情况下它可能不是一台服务器，而是利用反向代理、负载均衡等技术组成的庞大集群。\n**软件**是提供 Web 服务的应用程序，通常会运行在硬件含义的服务器上。响应海量的客户端 HTTP 请求，处理磁盘上的网页、图片等静态文件，或者把请求转发给后面的 Tomcat、Node.js 等业务应用，返回动态的信息。\n\n### CDN\n\n浏览器通常不会直接连到服务器，中间会经过“重重关卡”，其中的一个重要角色就叫做 CDN。\n\nCDN，全称是“Content Delivery Network”，翻译过来就是“内容分发网络”。它应用了 HTTP 协议里的缓存和代理技术，代替源站响应客户端的请求。\n\nCDN 可以缓存源站的数据，可以找到离用户最近的节点，大幅度缩短响应时间。\n\n### HTML/WebService/WAF\n\nHTML 是 HTTP 协议传输的主要内容之一，它描述了超文本页面，用各种“标签”定义文字、图片等资源和排版布局，最终由浏览器“渲染”出可视化页面。\n\nWeb Service 是一种由 W3C 定义的应用服务开发规范，使用 client-server 主从架构，通常使用 WSDL 定义服务接口，使用 HTTP 协议传输 XML 或 SOAP 消息，它是一个基于 Web（HTTP）的服务架构技术，既可以运行在内网，也可以在适当保护后运行在外网。\n\nWAF 是“网络应用防火墙”。与硬件“防火墙”类似，它是应用层面的“防火墙”，专门检测 HTTP 流量，是防护 Web 应用的安全技术。\n\nWAF 通常位于 Web 服务器之前，可以阻止如 SQL 注入、跨站脚本等攻击，目前应用较多的一个开源项目是 ModSecurity，它能够完全集成进 Apache 或 Nginx。\n\n1. 互联网上绝大部分资源都使用 HTTP 协议传输；\n2. 浏览器是 HTTP 协议里的请求方，即 User Agent；\n3. 服务器是 HTTP 协议里的应答方，常用的有 Apache 和 Nginx；\n4. CDN 位于浏览器和服务器之间，主要起到缓存加速的作用；\n5. 爬虫是另一类 User Agent，是自动访问网络资源的程序。\n\n## HTTP世界全览 - 下\n\n与HTTP 相关的 TCP/IP、DNS、URI、HTTPS 等相关协议介绍。\n\n### TCP/IP\n\nTCP/IP 协议实际上是一系列网络通信协议的统称，其中最核心的两个协议是 TCP 和 IP，其他的还有 UDP、ICMP、ARP 等等，共同构成了一个复杂但有层次的协议栈。\n\n这个协议栈有四层，最上层是“应用层”，最下层是“链接层”，TCP 和 IP 则在中间：TCP 属于“传输层”，IP 属于“网际层”。\n\nIP 协议是“Internet Protocol”的缩写，主要目的是解决寻址和路由问题，以及如何在两点间传送数据包。IP 协议使用“IP 地址”的概念来定位互联网上的每一台计算机。\n\n现在我们使用的 IP 协议大多数是 v4 版，地址是四个用“.”分隔的数字，例如“192.168.0.1”，总共有 2^32，大约 42 亿个可以分配的地址。但互联网的快速发展让地址的分配管理很快就耗尽了，所以，就又出现了 v6 版，使用 8 组“:”分隔的数字作为地址，容量扩大了很多，有 2^128 个。\n\nTCP 协议是“Transmission Control Protocol”的缩写，意思是“传输控制协议”，它位于 IP 协议之上，基于 IP 协议提供可靠的、字节流形式的通信，是 HTTP 协议得以实现的基础。\n\n“可靠”是指保证数据不丢失，“字节流”是指保证数据完整，所以在 TCP 协议的两端可以如同操作文件一样访问传输的数据，就像是读写在一个密闭的管道里“流动”的字节。\n\nHTTP 是一个\"传输协议\"，但它不关心寻址、路由、数据完整性等传输细节，而要求这些工作都由下层来处理。因为互联网上最流行的是 TCP/IP 协议，而它刚好满足 HTTP 的要求，所以互联网上的 HTTP 协议就运行在了 TCP/IP 上，HTTP 也就可以更准确地称为“HTTP over TCP/IP”。\n\n### DNS\n\n域名系统（Domain Name System），为了将一串无意义的数字通过一串有意义的字符表示更好的记忆。\n\n在 DNS 中，“域名”（Domain Name）又称为“主机名”（Host），为了更好地标记不同国家或组织的主机，让名字更好记，所以被设计成了一个有层次的结构。\n\n域名用“.”分隔成多个单词，级别从左到右逐级升高，最右边的被称为“顶级域名”。如表示商业公司的“com”、表示教育机构的“edu”，表示国家的“cn”“uk”等。\n\n想要使用 TCP/IP 协议来通信仍然要使用 IP 地址，所以需要把域名做一个转换，“映射”到它的真实 IP，这就是“域名解析”。\n\n目前全世界有 13 组根 DNS 服务器，下面再有许多的顶级 DNS、权威 DNS 和更小的本地 DNS，逐层递归地实现域名查询。\n\nHTTP 协议中并没有明确要求必须使用 DNS，但实际上为了方便访问互联网上的 Web 服务器，通常都会使用 DNS 来定位或标记主机名，间接地把 DNS 与 HTTP 绑在了一起。\n\n### URI/URL\n\nURI（Uniform Resource Identifier），中文名称是 统一资源标识符，使用它就能够唯一地标记互联网上资源。\n\nURI 另一个更常用的表现形式是 URL（Uniform Resource Locator）， 统一资源定位符，也就是我们俗称的“网址”，它实际上是 URI 的一个子集，不过这两者几乎是相同的，差异不大，所以通常不会做严格的区分。\n\n如：\n```\nhttp://nginx.org/en/download.html\n```\n\n可以看到，URI 主要有三个基本的部分构成：\n\n1. 协议名：即访问该资源应当使用的协议，在这里是“http”；\n2. 主机名：即互联网上主机的标记，可以是域名或 IP 地址，在这里是“nginx.org”；\n3. 路径：即资源在主机上的位置，使用“/”分隔多级目录，在这里是“/en/download.html”。\n\n### HTTPS\n\nHTTPS 它的全称是“HTTP over SSL/TLS”，也就是运行在 SSL/TLS 协议上的 HTTP。\n\n这里是 SSL/TLS，而不是 TCP/IP，它是一个负责加密通信的安全协议，建立在 TCP/IP 之上，所以也是个可靠的传输协议，可以被用作 HTTP 的下层。HTTPS 相当于“HTTP+SSL/TLS+TCP/IP”。\n\nSSL 的全称是“Secure Socket Layer”，由网景公司发明，当发展到 3.0 时被标准化，改名为 TLS，即“Transport Layer Security”，但由于历史的原因还是有很多人称之为 SSL/TLS，或者直接简称为 SSL。\n\nSSL 使用了许多密码学最先进的研究成果，综合了对称加密、非对称加密、摘要算法、数字签名、数字证书等技术，能够在不安全的环境中为通信的双方创建出一个秘密的、安全的传输通道，为 HTTP 套上一副坚固的盔甲。\n\n浏览器地址栏，如果有一个小锁头标志，那就表明网站启用了安全的 HTTPS 协议，而 URI 里的协议名，也从“http”变成了“https”。\n\n### 代理\n\n代理（Proxy）是 HTTP 协议中请求方和应答方中间的一个环节，作为“中转站”，既可以转发客户端的请求，也可以转发服务器的应答。\n\n代理有很多的种类，常见的有：\n\n1. 匿名代理：完全“隐匿”了被代理的机器，外界看到的只是代理服务器；\n2. 透明代理：顾名思义，它在传输过程中是“透明开放”的，外界既知道代理，也知道客户端；\n3. 正向代理：靠近客户端，代表客户端向服务器发送请求；\n4. 反向代理：靠近服务器端，代表服务器响应客户端的请求；\n\nCDN，实际上就是一种代理，它代替源站服务器响应客户端的请求，通常扮演着透明代理和反向代理的角色。\n\n由于代理在传输过程中插入了一个“中间层”，所以可以在这个环节做很多事情，比如：\n\n1. 负载均衡：把访问请求均匀分散到多台机器，实现访问集群化；\n2. 内容缓存：暂存上下行的数据，减轻后端的压力；\n3. 安全防护：隐匿 IP, 使用 WAF 等工具抵御网络攻击，保护被代理的机器；\n4. 数据处理：提供压缩、加密等额外的功能。\n\n关于 HTTP 的代理还有一个特殊的“代理协议”（proxy protocol），它由知名的代理软件 HAProxy 制订。\n\n### 小结\n\n1. TCP/IP 是网络世界最常用的协议，HTTP 通常运行在 TCP/IP 提供的可靠传输基础上；\n2. DNS 域名是 IP 地址的等价替代，需要用域名解析实现到 IP 地址的映射；\n3. URI 是用来标记互联网上资源的一个名字，由“协议名 + 主机名 + 路径”构成，俗称 URL；\n4. HTTPS 相当于“HTTP+SSL/TLS+TCP/IP”，为 HTTP 套了一个安全的外壳；\n5. 代理是 HTTP 传输过程中的“中转站”，可以实现缓存加速、负载均衡等功能。\n\n\n### 小贴士\n\n* IP 协议曾经有v1,v2, v3等早期版本，但因为不够完善而没有对外发布。而v5 则是仅用于实验室内部研究，从未公开，所以我们看到的只有v4和v6两个版本。\n* 2011年2月互联网组织ICANN 正式宣布IPV4 地址被\"用尽\"\n* 如果使用 UNIX/Linux 操作系统，HTTP可以运行在本机的 UNIX Domain Socket 上，它也是一种进程间通信机制，但也可以满足HTTP 对下层对可靠传输要求，所以就成了\"HTTP over UNIX Domain Soocket\"。\n\n\n## 常说的“四层”和“七层”到底是什么？\n\nTCP/IP 协议，它是 HTTP 协议的下层协议，负责具体的数据传输工作。强调了 TCP/IP 协议是一个 **“有层次的协议栈”**。\n\n### TCP/IP 网络分层模型\n\nTCP/IP 创造性地提出了“分层”的概念，把复杂的网络通信划分出多个层次，再给每一个层次分配不同的职责，用“分而治之”的思想把一个“大麻烦”拆分成了数个“小麻烦”，从而解决了网络通信的难题。\n\n如图所示：\n\n<img src=\"/images/http/gk/tcp-layer.png\" art=\"tcp_layer\" width=\"400px\">\n\nTCP/IP 协议总共有四层，每一层需要下层的支撑，同时又支撑着上层，任何一层被抽掉都可能会导致整个协议栈坍塌。\n\n从下往上看：\n\n第一层叫“链接层”（link layer），负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标记网络上的设备，所以有时候也叫 MAC 层。\n\n第二层叫“网际层”或者“网络互连层”（internet layer），IP 协议就处在这一层。因为 IP 协议定义了“IP 地址”的概念，所以就可以在“链接层”的基础上，用 IP 地址取代 MAC 地址，把许许多多的局域网、广域网连接成一个虚拟的巨大网络，在这个网络里找设备时只要把 IP 地址再“翻译”成 MAC 地址就可以了。\n\n第三层叫“传输层”（transport layer），这个层次协议的职责是保证数据在 IP 地址标记的两点之间“可靠”地传输，是 TCP 协议工作的层次，另外还有它的一个“小伙伴”UDP。\n\nTCP 是一个有状态的协议，需要先与对方建立连接然后才能发送数据，而且保证数据不丢失不重复。而 UDP 则比较简单，它无状态，不用事先建立连接就可以任意发送数据，但不保证数据一定会发到对方。两个协议的另一个重要区别在于数据的形式。TCP 的数据是连续的“字节流”，有先后顺序，而 UDP 则是分散的小数据包，是顺序发，乱序收。\n\n协议栈的第四层叫“应用层”（application layer），有各种面向具体应用的协议。例如 Telnet、SSH、FTP、SMTP 等等，当然还有 HTTP。\n\nMAC 层的传输单位是帧（frame），IP 层的传输单位是包（packet），TCP 层的传输单位是段（segment），HTTP 的传输单位则是消息或报文（message）。但这些名词并没有什么本质的区分，可以统称为数据包。\n\n\n### OSI 网络分层模型\n\nOSI，全称是“开放式系统互联通信参考模型”（Open System Interconnection Reference Model）。\n\nOSI 模型分成了七层，部分层次与 TCP/IP 很像，从下到上分别是：\n\n<img src=\"/images/http/gk/osi-layer.png\" art=\"osi_layer\" width=\"400px\">\n\n1. 第一层：物理层，网络的物理形式，例如电缆、光纤、网卡、集线器等等；\n2. 第二层：数据链路层，它基本相当于 TCP/IP 的链接层；\n3. 第三层：网络层，相当于 TCP/IP 里的网际层；\n4. 第四层：传输层，相当于 TCP/IP 里的传输层；\n5. 第五层：会话层，维护网络中的连接状态，即保持会话和同步；\n6. 第六层：表示层，把数据转换为合适、可理解的语法和语义；\n7. 第七层：应用层，面向具体的应用传输数据。\n\n### 两个分层模型的映射关系\n\n<img src=\"/images/http/gk/tcp-osi-map.png\" art=\"tcp-osi-map\" width=\"400px\">\n\n1. 第一层：物理层，TCP/IP 里无对应；\n2. 第二层：数据链路层，对应 TCP/IP 的链接层；\n3. 第三层：网络层，对应 TCP/IP 的网际层；\n4. 第四层：传输层，对应 TCP/IP 的传输层；\n5. 第五、六、七层：统一对应到 TCP/IP 的应用层。\n\nOSI 的分层模型在四层以上分的太细，而 TCP/IP 实际应用时的会话管理、编码转换、压缩等和具体应用经常联系的很紧密，很难分开。例如，HTTP 协议就同时包含了连接管理和数据格式定义\n\n“四层负载均衡”就是指工作在传输层上，基于 TCP/IP 协议的特性，例如 IP 地址、端口号等实现对后端服务器的负载均衡。\n\n“七层负载均衡”就是指工作在应用层上，看到的是 HTTP 协议，解析 HTTP 报文里的 URI、主机名、资源类型等数据，再用适当的策略转发给后端服务器。\n\n### TCP/IP 协议栈的工作方式\n\n\n发送数据的过程：\n\n1. 在应用层，HTTP 协议为它加一个 HTTP 专用附加数据\n2. 在 TCP 层给数据再次打包，加上了 TCP 头\n3. IP 层为TCP 数据包加上了 IP 头\n4. MAC 层对TCP 数据包加上MAC 头\n5. 之后经过网络传输到达重点\n6. 目标服务经过拆包 去掉 mac头 ip头和TCP头 获取到真正数据\n\nHTTP 协议的传输过程就是这样通过协议栈逐层向下，每一层都添加本层的专有数据，层层打包，然后通过下层发送出去。\n\n接收数据则是相反的操作，从下往上穿过协议栈，逐层拆包，每层去掉本层的专有头，上层就会拿到自己的数据。\n\n### 小结\n\n1. TCP/IP 分为四层，核心是二层的 IP 和三层的 TCP，HTTP 在第四层；\n2. OSI 分为七层，基本对应 TCP/IP，TCP 在第四层，HTTP 在第七层；\n3. OSI 可以映射到 TCP/IP，但这期间一、五、六层消失了；\n4. 日常交流的时候我们通常使用 OSI 模型，用四层、七层等术语；\n5. HTTP 利用 TCP/IP 协议栈逐层打包再拆包，实现了数据传输，但下面的细节并不可见。\n\n辨别四层和七层比较好的（但不是绝对的）小窍门，“两个凡是”：\n* 凡是由操作系统负责处理的就是四层或四层以下\n* 凡是需要由应用程序（也就是你自己写代码）负责处理的就是七层。\n\n### 小贴士\n\n1. MAC地址（Media Access Control Address）也称为局域网地址，可以唯一的标识一个网卡，也就同时标识了此网卡的设备。\n2. 在 TCP/IP 协议栈之外，还有一些协议位于OSI 五层和六层的，例如：UNIX 域套接字就可以认为是在五层。\n\n## 域名里有哪些门道？\n\n### 域名的形式\n\n域名是一个有层次的结构，是一串用“.”分隔的多个单词，最右边的被称为“顶级域名”，然后是“二级域名”，层级关系向左依次降低。\n\n最左边的是主机名，通常用来表明主机的用途，比如“www”表示提供万维网服务、“mail”表示提供邮件服务。\n\n如： time.geekbang.org 这里的“org”就是顶级域名，“geekbang”是二级域名，“time”则是主机名。\n\n域名不仅能够代替 IP 地址，还有许多其他的用途\n\n在 Apache、Nginx 这样的 Web 服务器里，域名可以用来标识虚拟主机，决定由哪个虚拟主机来对外提供服务，比如在 Nginx 里就会使用“server_name”指令：\n\n```\nserver {\n    listen 80;                       #监听80端口\n    server_name  time.geekbang.org;  #主机名是time.geekbang.org\n    ...\n}\n```\n\n### 域名的解析\n\n就像 IP 地址必须转换成 MAC 地址才能访问主机一样，域名也必须要转换成 IP 地址，这个过程就是“域名解析”。\n\nDNS 的核心系统是一个三层的树状、分布式服务，基本对应域名的结构：\n\n1. 根域名服务器（Root DNS Server）：管理顶级域名服务器，返回“com”“net”“cn”等顶级域名服务器的 IP 地址；\n2. 顶级域名服务器（Top-level DNS Server）：管理各自域名下的权威域名服务器，比如 com 顶级域名服务器可以返回 apple.com 域名服务器的 IP 地址；\n3. 权威域名服务器（Authoritative DNS Server）：管理自己域名下主机的 IP 地址，比如 apple.com 权威域名服务器可以返回 www.apple.com 的 IP 地址。\n\n<img src=\"/images/http/gk/dns.png\" art=\"dns\" width=\"400px\">\n\n目前全世界共有 13 组根域名服务器，又有数百台的镜像，保证一定能够被访问到。\n\n例如，你要访问“www.apple.com”，就要进行下面的三次查询：\n\n1. 访问根域名服务器，它会告诉你“com”顶级域名服务器的地址；\n2. 访问“com”顶级域名服务器，它再告诉你“apple.com”域名服务器的地址；\n3. 最后访问“apple.com”域名服务器，就得到了“www.apple.com”的地址。\n\n在核心 DNS 系统之外，还有两种手段用来减轻域名解析的压力，并且能够更快地获取结果，基本思路就是“缓存”。\n\n许多大公司、网络运行商都会建立自己的 DNS 服务器，作为用户 DNS 查询的代理，代替用户访问核心 DNS 系统。这些“野生”服务器被称为“非权威域名服务器”，可以缓存之前的查询结果，如果已经有了记录，就无需再向根服务器发起查询，直接返回对应的 IP 地址。\n\n这些 DNS 服务器的数量要比核心系统的服务器多很多，而且大多部署在离用户很近的地方。比较知名的 DNS 有 Google 的“8.8.8.8”，Microsoft 的“4.2.2.1”，还有 CloudFlare 的“1.1.1.1”等等。\n\n其次，操作系统里也会对 DNS 解析结果做缓存，如果你之前访问过“www.apple.com”，那么下一次在浏览器里再输入这个网址的时候就不会再跑到 DNS 那里去问了，直接在操作系统里就可以拿到 IP 地址。\n\n另外，操作系统里还有一个特殊的“主机映射”文件，通常是一个可编辑的文本，在 Linux 里是“/etc/hosts”，在 Windows 里是“C:\\WINDOWS\\system32\\drivers\\etc\\hosts”，如果操作系统在缓存里找不到 DNS 记录，就会找这个文件。\n\n有了上面的“野生”DNS 服务器、操作系统缓存和 hosts 文件后，很多域名解析的工作直接在本地或本机就能解决，不仅方便了用户，也减轻了各级 DNS 服务器的压力。\n\n如图：完整地表示了现在的 DNS 架构。\n\n<img src=\"/images/http/gk/dns-now.png\" art=\"dns-now\" width=\"400px\">\n\n在 Nginx 里有这么一条配置指令“resolver”，它就是用来配置 DNS 服务器的，如果没有它，那么 Nginx 就无法查询域名对应的 IP，也就无法反向代理到外部的网站。\n```\nresolver 8.8.8.8 valid=30s;  #指定Google的DNS，缓存30秒\n```\n\n### 域名的“新玩法”\n\n第一种，也是最简单的，“重定向”。因为域名代替了 IP 地址，所以可以让对外服务的域名不变，而主机的 IP 地址任意变动。当主机有情况需要下线、迁移时，可以更改 DNS 记录，让域名指向其他的机器。\n\n第二种，因为域名是一个名字空间，所以可以使用 bind9 等开源软件搭建一个在内部使用的 DNS，作为名字服务器。这样我们开发的各种内部服务就都用域名来标记，比如数据库服务都用域名“mysql.inner.app”，商品服务都用“goods.inner.app”，发起网络通信时也就不必再使用写死的 IP 地址了，可以直接用域名。\n\n第三种“玩法”包含了前两种，也就是基于域名实现的负载均衡。\n\n这种“玩法”也有两种方式，两种方式可以混用。\n\n第一种方式，因为域名解析可以返回多个 IP 地址，所以一个域名可以对应多台主机，客户端收到多个 IP 地址后，就可以自己使用轮询算法依次向服务器发起请求，实现负载均衡。\n\n第二种方式，域名解析可以配置内部的策略，返回离客户端最近的主机，或者返回当前服务质量最好的主机，这样在 DNS 端把请求分发到不同的服务器，实现负载均衡。\n\n**恶意的“玩法”**\n\n* “域名屏蔽”，对域名直接不解析，返回错误，让你无法拿到 IP 地址，也就无法访问网站；\n* “域名劫持”，也叫“域名污染”，你要访问 A 网站，但 DNS 给了你 B 网站。\n\n### 小结\n\n1. 域名使用字符串来代替 IP 地址，方便用户记忆，本质上一个名字空间系统；\n2. DNS 就像是我们现实世界里的电话本、查号台，统管着互联网世界里的所有网站，是一个“超级大管家”；\n3. DNS 是一个树状的分布式查询系统，但为了提高查询效率，外围有多级的缓存；\n4. 使用 DNS 可以实现基于域名的负载均衡，既可以在内网，也可以在外网。\n\n### 小贴士\n\n域名的总长度限制在253个字符以内，而每一级域名长度不能超过63个字符。\n\n### 课程来源\n\nhttps://time.geekbang.org/column/intro/100029001\n\n欢迎大家订购，一块儿学习，共同进步。","tags":["http","TCP/IP"],"categories":["http"]},{"title":"rpc的核心原理-rpc的通信流程","url":"/2021/06/02/rpc的核心原理-rpc的通信流程/","content":"\nRPC 是解决分布式系统通信问题的一大利器。\n\n分布式系统中的网络通信一般都会采用四层的 TCP 协议或七层的 HTTP 协议，前者占大多数，这主要得益于 TCP 协议的稳定性和高效性。网络通信说起来简单，但实际上是一个非常复杂的过程，这个过程主要包括：对端节点的查找、网络连接的建立、传输数据的编码解码以及网络连接的管理等等，每一项都很复杂。\n\n<!-- more -->\n\n而 RPC 对网络通信的整个过程做了完整包装，在搭建分布式系统时，它会使网络通信逻辑的开发变得更加简单，同时也会让网络通信变得更加安全可靠。\n\n### 什么是RPC?\n\nRPC 的全称是 Remote Procedure Call，即远程过程调用。简单从字面上来看，是指要跨机器而非本机，所以需要用到网络编程才能实现，但是不是只要通过网络通信访问到另一台机器的应用程序，就可以称之为 RPC 调用了？显然并不够。\n\nRPC 是帮助我们屏蔽网络编程细节，实现调用远程方法就跟调用本地（同一个项目中的方法）一样的体验，我们不需要因为这个方法是远程调用就需要编写很多与业务无关的代码。\n\nRPC 的作用就是体现在两个方面：\n\n* 屏蔽远程调用跟本地调用的区别，让我们感觉就是调用项目内的方法；\n* 隐藏底层网络通信的复杂性，让我们更专注于业务逻辑。\n\n### RPC的通信流程\n\n一个完整的 RPC 会涉及到哪些步骤呢？\n\nRPC 是一个远程调用，需要通过网络来传输数据，并且 RPC 常用于业务系统之间的数据交互，需要保证其可靠性，所以 RPC 一般默认采用 TCP 来传输。我们常用的 HTTP 协议也是建立在 TCP 之上的。\n\n调用方持续地把请求参数序列化成二进制后，经过 TCP 传输给了服务提供方。服务提供方从 TCP 通道里面收到二进制数据，那如何知道一个请求的数据到哪里结束，是一个什么类型的请求呢？这里就需要用到相关协议，而协议的作用就是做相关规定和约束。\n\n大多数的协议会分成两部分，分别是数据头和消息体。数据头一般用于身份识别，包括协议标识、数据大小、请求类型、序列化类型等信息；消息体主要是请求的业务参数信息和扩展属性等。\n\n根据协议格式，服务提供方就可以正确地从二进制数据中分割出不同的请求来，同时根据请求类型和序列化类型，把二进制的消息体逆向还原成请求对象。这个过程叫作“反序列化”。\n\n服务提供方再根据反序列化出来的请求对象找到对应的实现类，完成真正的方法调用，然后把执行结果序列化后，回写到对应的 TCP 通道里面。调用方获取到应答的数据包后，再反序列化成应答对象，这样调用方就完成了一次 RPC 调用。\n\n### 完整的RPC通信流程\n\n如Spring的AOP技术，其核心是采用动态代理的技术，通过字节码增强对方法进行拦截增强，以便于增加需要的额外处理逻辑。其实这个技术也可以应用到 RPC 场景来解决我们刚才面临的问题。\n\n由服务提供者给出业务接口声明，在调用方的程序里面，RPC 框架根据调用的服务接口提前生成动态代理实现类，并通过依赖注入等技术注入到声明了该接口的相关业务逻辑里面。该代理实现类会拦截所有的方法调用，在提供的方法处理逻辑里面完成一整套的远程调用，并把远程调用结果返回给调用方，这样调用方在调用远程方法的时候就获得了像调用本地接口一样的体验。\n\n![rpc_procedure](/images/golang/rpc/rpc-call-procedure.jpg)\n\n\n\n\n### RPC在架构中的位置\n\n如刚才所讲，RPC 是解决应用间通信的一种方式，而无论是在一个大型的分布式应用系统还是中小型系统中，应用架构最终都会从“单体”演进成“微服务化”，整个应用系统会被拆分为多个不同功能的应用，并将它们部署在不同的服务器中，而应用之间会通过 RPC 进行通信，可以说 RPC 对应的是整个分布式应用系统，就像是“经络”一样的存在。\n\nRPC 框架能够帮助我们解决系统拆分后的通信问题，并且能让我们像调用本地一样去调用远程方法。\n\n利用 RPC 我们不仅可以很方便地将应用架构从“单体”演进成“微服务化”，而且还能解决实际开发过程中的效率低下、系统耦合等问题，这样可以使得我们的系统架构整体清晰、健壮，应用可运维度增强。\n\n### 总结\n\nRPC 就是提供一种透明调用机制，让使用者不必显式地区分本地调用和远程调用。RPC 虽然可以帮助开发者屏蔽远程调用跟本地调用的区别，但毕竟涉及到远程网络通信，所以这里还是有很多使用上的区别，比如：\n\n* 调用过程中超时了怎么处理业务？\n* 什么场景下最适合使用 RPC？\n* 什么时候才需要考虑开启压缩？\n\n### 课程来源\n\nhttps://time.geekbang.org/column/intro/100046201\n\n欢迎大家订购，一块儿学习，共同进步。","tags":["rpc"],"categories":["RPC"]},{"title":"go实现各类限流算法","url":"/2021/05/30/go实现各类限流算法/","content":"\n## 介绍\n限流是一种编程中常用的保护服务正常运行的一种方案；为了应对激增的流量，防止服务被击垮，经常使用某种算法来对流量进行某种限流，以保证后端服务的正常运行。\n\n本文介绍 计数器、令牌桶算法和楼桶算法及它们之间的优缺点。\n\n<!-- more -->\n\n## 计数器\n```\npackage main\n\nimport (\n\t\"log\"\n\t\"sync\"\n\t\"time\"\n)\n\n// Counter Counter\ntype Counter struct {\n\trate  int\n\tbegin time.Time\n\tcycle time.Duration\n\tcount int\n\tlock  sync.Mutex\n}\n\n// Set Set\nfunc (c *Counter) Set(r int, cycle time.Duration) {\n\tc.rate = r\n\tc.begin = time.Now()\n\tc.cycle = cycle\n\tc.count = 0\n}\n\n// Reset Reset\nfunc (c *Counter) Reset(t time.Time) {\n\tc.begin = t\n\tc.count = 0\n}\n\n// Allow Allow\nfunc (c *Counter) Allow() bool {\n\tc.lock.Lock()\n\tdefer c.lock.Unlock()\n\n\tif c.count == c.rate {\n\t\tnow := time.Now()\n\t\tif now.Sub(c.begin) >= c.cycle {\n\t\t\tc.Reset(now)\n\t\t\treturn true\n\t\t} else {\n\t\t\treturn false\n\t\t}\n\t} else {\n\t\tc.count++\n\t\treturn true\n\t}\n\n}\n\nfunc main() {\n\tvar wg sync.WaitGroup\n\tlr := new(Counter)\n\tlr.Set(3, time.Second)\n\tfor i := 0; i < 10; i++ {\n\t\twg.Add(1)\n\t\tlog.Println(\"创建请求:\", i)\n\t\tgo func(i int) {\n\t\t\tif lr.Allow() {\n\t\t\t\tlog.Println(\"request allw: \", i)\n\t\t\t}\n\t\t\twg.Done()\n\t\t}(i)\n\t\ttime.Sleep(200 * time.Millisecond)\n\t}\n\twg.Wait()\n}\n```\n\n这个算法虽然简单，但是有一个十分致命的问题，那就是临界问题，我们看下图：\n![counter](/images/golang/limit/counter.png)\n从上图中我们可以看到，假设有一个恶意用户，他在0:59时，瞬间发送了100个请求，并且1:00又瞬间发送了100个请求，那么其实这个用户在 1秒里面，瞬间发送了200个请求。我们刚才规定的是1分钟最多100个请求，也就是每秒钟最多1.7个请求，用户通过在时间窗口的重置节点处突发请求， 可以瞬间超过我们的速率限制。用户有可能通过算法的这个漏洞，瞬间压垮我们的应用。\n## 令牌桶算法\n\n是一个存放固定容量令牌的桶，按照固定速率往桶里添加令牌。令牌桶算法的描述如下：\n\n<img src=\"/images/golang/limit/token-bucket.png\" art=\"token-bucket\" width=\"500px\">\n\n* 假设限制2r/s，则按照500毫秒的固定速率往桶中添加令牌。\n* 桶中最多存放 b 个令牌，当桶满时，新添加的令牌被丢弃或拒绝。\n* 当一个 n 个字节大小的数据包到达，将从桶中删除n 个令牌，接着数据包被发送到网络上。\n* 如果桶中的令牌不足 n 个，则不会删除令牌，且该数据包将被限流（要么丢弃，要么缓冲区等待）。\n\n官方实现：https://pkg.go.dev/golang.org/x/time/rate\n\n### 通过 time/rate 包实现\n```\n// 构建限流对象\n// NewLimiter returns a new Limiter that allows events up to rate r and permits\n// bursts of at most b tokens.\nfunc NewLimiter(r Limit, b int) *Limiter {\n    return &Limiter{\n        limit: r,\n        burst: b,\n    }\n}\n```\n\nAllow/AllowN 判断是否允许通过\n```\n// Allow is shorthand for AllowN(time.Now(), 1).\nfunc (lim *Limiter) Allow() bool {\n    return lim.AllowN(time.Now(), 1)\n}\n\n// AllowN reports whether n events may happen at time now.\n// Use this method if you intend to drop / skip events that exceed the rate limit.\n// Otherwise use Reserve or Wait.\nfunc (lim *Limiter) AllowN(now time.Time, n int) bool {\n    return lim.reserveN(now, n, 0).ok\n}\n```\n具体细节，请看官方实现。\n\n### 自己手动实现\n\ndemo示例：\n```\npackage main\n\nimport (\n\t\"math\"\n\t\"sync\"\n\t\"time\"\n)\n\ntype tokenBucket struct {\n\trate     int64 // 速率\n\tcapacity int64 // 桶容量\n\ttokens   int64 // 桶内token 个数\n\tlastTime time.Time\n\tlock sync.Mutex\n}\n\nfunc (t *tokenBucket) allow() bool {\n\tt.lock.Lock()\n\tdefer t.lock.Unlock()\n\tnow := time.Now()\n\tt.tokens = t.tokens + int64(now.Sub(t.lastTime).Seconds() * float64(t.rate))\n\tt.tokens = int64(math.Min(float64(t.tokens), float64(t.capacity)))\n\tif t.tokens > 0 {\n\t\tt.lastTime = now\n\t\tt.tokens--\n\t\treturn true\n\t}\n\treturn false\n}\n\nfunc NewTokenBucket(r, c int64) *tokenBucket {\n\treturn &tokenBucket{\n\t\trate:     r,\n\t\tcapacity: c,\n\t\ttokens:   0,\n\t\tlastTime: time.Now(),\n\t}\n}\n```\n\n测试，此时每5个请求，一个请求成功\n```\nfunc main() {\n\tt := NewTokenBucket(2, 5)\n\tfor i := 0; i < 20; i++ {\n\t\ttime.Sleep(time.Millisecond * 100)\n\t\tif ok := t.allow(); ok {\n\t\t\tfmt.Println(\"request allow!\")\n\t\t} else {\n\t\t\tfmt.Println(\"request deny!\")\n\t\t}\n\t}\n}\n\nrequest deny!\nrequest deny!\nrequest deny!\nrequest deny!\nrequest allow!\n...\n```\n\n## 漏桶算法\n\n作为计量工具(The Leaky Bucket Algorithm as a Meter)时，可以用于流量整形(Traffic Shaping)和流量控制(TrafficPolicing)，漏桶算法的描述如下：\n\n* 一个固定容量的漏桶，按照常量固定速率流出水滴。\n* 如果桶是空的，则不需流出水滴。\n* 可以以任意速率流入水滴到漏桶。\n* 如果流入水滴超出了桶的容量，则流入的水滴溢出了（被丢弃），而漏桶容量是不变的。\n\nleaky-bucket rate limit algorithm: \nhttps://pkg.go.dev/go.uber.org/ratelimit\n\n### uber ratelimit 官方实现\n```\nimport (\n\t\"fmt\"\n\t\"time\"\n\n\t\"go.uber.org/ratelimit\"\n)\n\nfunc main() {\n    rl := ratelimit.New(100) // per second\n\n    prev := time.Now()\n    for i := 0; i < 10; i++ {\n        // 此处会被阻塞，直到请求允许通过\n        // Take should block to make sure that the RPS is met.\n        now := rl.Take()\n        fmt.Println(i, now.Sub(prev))\n        prev = now\n    }\n\n    // Output:\n    // 0 0\n    // 1 10ms\n    // 2 10ms\n    // 3 10ms\n    // 4 10ms\n    // 5 10ms\n    // 6 10ms\n    // 7 10ms\n    // 8 10ms\n    // 9 10ms\n}\n```\n\n### 自己实现\n```\npackage main\n\nimport (\n\t\"math\"\n\t\"sync\"\n\t\"time\"\n)\n\ntype LeakBucket struct {\n\trate       float64 // 固定每秒出水率\n\tcapacity   float64 // 桶容量\n\twater      float64 // 桶中当前水量\n\tlastLeakMs int64   // 上次漏水时间戳\n\tlock       sync.Mutex\n}\n\nfunc (l *LeakBucket) Allow() bool {\n\tl.lock.Lock()\n\tdefer l.lock.Unlock()\n\n\tnow := time.Now().UnixNano() / 1e6\n\teclipse := float64(now-l.lastLeakMs) * l.rate / 1000\n\tl.water = l.water - eclipse\n\tl.water = math.Max(0, l.water)\n\tif (l.water + 1) < l.capacity {\n\t\tl.lastLeakMs = now\n\t\tl.water++\n\t\treturn true\n\t} else {\n\t\treturn false\n\t}\n}\n\nfunc newBucket(r float64, c float64) *LeakBucket {\n\treturn &LeakBucket{\n\t\trate:       r,\n\t\tcapacity:   c,\n\t\twater:      0,\n\t\tlastLeakMs: time.Now().UnixNano() / 1e6,\n\t}\n}\n```\n\n计数器\n漏桶算法 流出的速率是固定的，与令牌桶算法不同的是，令牌桶算法是放入的速率固定，取出的速率不固定，所以令牌桶算法支持流量的爆发。\n\n\n\n","tags":["golang","limiter"],"categories":["golang"]},{"title":"在线小工具","url":"/2021/05/29/在线小工具/","content":"\n本文记录了编程人员常用的工具集合，方便自己编程使用，也作为小工具箱方便大家查找。\n\n### 工具转换\n\n* [时间戳](https://tool.lu/timestamp/)\n* [很全的在线工具集合](https://tool.lu/)\n<!-- more -->\n* [正则表达式工具](https://regexr.com/)\n* [markdown在线编辑器](https://tool.lu/markdown/)\n* [json格式化](https://www.json.cn/)\n* [json 转 struct](https://oktools.net/json2go)\n* [base64 转图片](https://tool.jisuapi.com/base642pic.html)\n* [正则表达式生成](http://tool.chinaz.com/tools/regexgenerate)\n* [图片压缩](https://tinypng.com/)\n\n### 算法与数据结构\n\n* [数据结构动态演示](https://www.cs.usfca.edu/~galles/visualization/Algorithms.html)\n* [数据结构和算法动态可视化：visualgo](https://visualgo.net/zh)\n\n\n### 查询类\n\n* [IP 地址查询](https://www.ipaddress.com/)\n* [内容差异比较](https://www.diffchecker.com/diff)\n* [网站证书信息查询](http://web.chacuo.net/netsslctcheck)\n* [聚查网](www.jucha.com)\n\n### 图标\n\n* [阿里巴巴矢量图标库](https://www.iconfont.cn/)\n\n### 在线作图\n\n* [ProcessOn](https://www.processon.com/;jsessionid=63AD3093802D99FD12D81FBD3881824F.jvm1)\n\n### 其他\n\n* [jetbrains激活码](http://idea.medeming.com/jet/)\n* [nginx 证书生成](https://certbot.eff.org/lets-encrypt/centosrhel7-nginx)\n* [中文智能转换变量](https://unbug.github.io/codelf/)\n* [微信公众号排版编辑](https://editor.mdnice.com/)\n* [网站代理](http://www.ddung.org/daili/)\n* [mac 软件下载](https://xclient.info/)\n* [开源操作系统最新信息](https://distrowatch.com/)","tags":["tool"],"categories":["tool"]},{"title":"http 准则","url":"/2021/05/27/http准则/","content":"\n## HTTP 准则\n\n本文档介绍了 Google API 如何与不同的 HTTP 版本和实现结合使用。\n\n## 使用传输协议 (HTTP/*)\n\n<!-- more -->\n\n本部分介绍 Cloud API 可用于在客户端和服务器之间进行通信的支持的传输协议（通常是某个版本的 HTTP），以及我们为您建议的协议使用方式。我们将在下一部分详细介绍请求和响应的结构。\n\n### HTTP 语义\n\n开发 API 客户端代码时，请遵循标准 [HTTP 协议语义](https://datatracker.ietf.org/doc/html/rfc7231)。服务器端代理或 API 堆栈可能仅支持标准 HTTP 功能的子集，并且还可能支持其向后兼容的版本。\n\n需要由 API 的服务器端实现处理的 HTTP 协议语义由服务器堆栈控制。仅当这些功能明确记录为 API 规范（例如缓存支持）的一部分时，才能依赖此类语义。\n\n### HTTP 版本\n\n客户端可以使用客户端平台或其客户端网络允许或者与服务器端代理协商的任何 HTTP/* 协议。支持的协议包括 HTTP/1.0、HTTP/1.1、SPDY/*、HTTP/2 和 QUIC。\n\n某些 API 功能可能只有较新版本的 HTTP 协议（例如服务器推送和优先级）才支持；部分功能仅使用 HTTP/2（例如全双工流式传输）完全指定。如果您需要将这些功能中的任何功能作为 API 规范的一部分，请注意不同 HTTP 版本的限制。\n\n通常，为了提高性能和网络故障的恢复能力，建议使用 HTTP/2。\n\n### 渠道\n\n信道是指 L4 网络连接（TCP 或 UDP 套接字）。客户端应用不应该针对在运行时中如何使用信道来提供 HTTP 请求作出任何假设。在几乎所有情况下，信道都是由代表服务器进程的代理来终止。\n\n对于 HTTP/1.1 客户端，应始终重复使用 TCP 连接 (Connection: Keep-Alive)；为了获得更好的性能，HTTP 客户端库也可能会管理连接池。请不要通过相同的 TCP 连接传递请求。如需了解详情，请参阅 [HTTP 和 TCP](https://github.com/httpwg/wiki/wiki/TCP)。\n\n现代浏览器都使用 SPDY/*、HTTP/2 或 QUIC 进行通信，它们通过单个信道多路传输请求。除非服务器实现限制来自单个客户端的并发 HTTP 请求数 例如，针对单个源的 100 个 HTTP/2 信息流），否则传统的连接限制 (2-10) 永远不应该成为问题。\n\n### HTTPS\n\n客户端可以通过 API 规范支持的 HTTPS 或 HTTP 访问 API。TLS 协商和 TLS 版本对客户端应用是透明的。默认情况下，Google API 仅接受 HTTPS 流量。\n\n## 请求/响应格式\n\n### 请求网址\n\nJSON-REST 映射支持网址编码形式的请求数据，HTTP 请求和响应主体使用 application/json 作为 Content-Type。HTTP 主体使用 JSON 数组来支持流式 RPC 方法，JSON 数组可能包含任意数量的 JSON 消息或错误状态 JSON 消息。\n\n### 长请求网址\n\n网址具有实际长度限制，通常在 2k 到 8k 之间。此限制由一些浏览器和代理强制执行。如果您的 API 使用网址超过长度限制的 GET 请求，浏览器可能会拒绝此类请求。要避开此限制，客户端代码应使用 Content-Type 为 application/x-www-form-urlencoded 的 POST 请求，且 HTTP 标头为 X-HTTP-Method-Override: GET。该方法也适用于 DELETE 请求。\n\n### HTTP 方法（动词）\n\n如果请求网址符合 REST 模型，则将其 HTTP 方法指定为 API 规范的一部分。特别是，每种 API 方法都必须符合基于 API 方法映射到的特定 HTTP 动词的 HTTP 协议的要求。如需了解详情，请参阅[超文本传输协议](https://datatracker.ietf.org/doc/html/rfc2616#section-9)规范和 [PATCH 方法](https://datatracker.ietf.org/doc/html/rfc5789) RFC。\n\n[安全方法](https://datatracker.ietf.org/doc/html/rfc2616#section-9.1.1)（如 HTTP GET 和 HEAD）不应表示检索以外的操作。具体来说，HTTP GET 应该安全，不应对客户端产生任何显而易见的副作用。\n\nHTTP 中的[幂等性](https://datatracker.ietf.org/doc/html/rfc2616#section-9.1.2)意味着多个相同请求产生的副作用与单个请求相同。GET、PUT 和 DELETE 是与风格指南相关的幂等 HTTP 方法。请注意，幂等性仅通过服务器副作用的形式表示，并未指定有关响应的任何内容。特别是对于不存在的资源，DELETE 应该返回 404 (Not Found)。\n\nHTTP POST 和 PATCH 既不安全也不具有幂等性。（PATCH 在 [RFC 5789](https://datatracker.ietf.org/doc/html/rfc5789) 中引入）\n\n|  HTTP 动词   | 安全  | 幂等   |\n|  ----  | ----  | ----  |\n| [GET](https://datatracker.ietf.org/doc/html/rfc2616#section-9.3)  | 是 | 是 |\n| [PUT](https://datatracker.ietf.org/doc/html/rfc2616#section-9.6)  | - | 是 |\n| [DELETE](https://datatracker.ietf.org/doc/html/rfc2616#section-9.7)  | - | 是 |\n| [POST](https://datatracker.ietf.org/doc/html/rfc2616#section-9.5)  | - | - |\n| [PATCH](https://datatracker.ietf.org/doc/html/rfc5789)  | - | - |\n\n### 负载格式\n\n* 请求和响应应共享相同的 Content-Type，除非请求是带有 application/x-www-form-urlencoded 主体的 GET 或 POST。\n* JSON 在 application/json MIME 类型中受支持。从 proto3 到 JSON 的映射在 [JSON 映射](https://developers.google.com/protocol-buffers/docs/proto3?hl=en#json)中正式指定。\n* 根据用于将请求字段映射到查询参数的相同 REST 样式映射规则，可以使用表单参数 (POST) 代替网址查询参数 (GET)。支持的 Content-Type 为 application/x-www-form-urlencoded。\n\n## 流式\n\n### 半双工与全双工\n\nHTTP 是一种请求响应协议，允许通过面向信息流的不同传输协议（如 TCP (HTTP/1.x)）或其多路复用变体 (SPDY、HTTP/2、QUIC) 传递其请求或响应主体。\n\n作为客户端开发人员，您的应用可以采用流式传输模式生成请求主体，即客户端流式传输。同样地，应用也可以采用流式传输模式使用响应主体，即服务器流式传输。\n\n但是，HTTP 规范未指定在请求正文仍处于挂起状态时是否允许服务器流式传输回响应正文（错误响应除外）。这种语义称为全双工流式传输。尽管许多 HTTP 客户端/服务器/代理软件确实支持全双工流式传输，即使 HTTP/1.1 也支持，但为了避免出现任何互操作性问题，基于 HTTP 的 Cloud API 仅限于半双工流式传输。\n\n默认情况下，Cloud API 中的出价 Bidi 流式传输方法会采用全双工语义。 也就是说，使用 HTTP 调用这样的方法是不安全的。如果流式传输方法仅为半双工（由服务器强制执行），则 API 文档应明确指定半双工行为。\n\n对于浏览器客户端，标准 HTTP 语义进一步受浏览器网络 API 的限制。目前，浏览器仅通过 XHR 或 Fetch 支持服务器流式传输通常遵循传输级别的帧处理方式）。Fetch API 可以使用 [whatwg 流](https://github.com/whatwg/streams)。\n\n由于浏览器的限制，需要浏览器支持的 Cloud API 必须避免采用客户端流式传输以及全双工流式传输，或者为浏览器客户端提供单独的 API。\n\n一般来说，通过互联网进行客户端流式传输不如服务器流式传输有用。这是因为使用客户端流式传输通常会导致有状态服务，这会对负载平衡造成负面影响，让系统更容易出现故障或受到攻击。另一方面，服务器流式传输可能很有用，因为它可以显着减少有长时间 RTT 延迟的网络上的延迟时间。\n\n### 消息编码\n\nJSON 消息在流式传输时将作为 JSON 消息数组进行编码。请求或响应正文将作为有效的 JSON MIME 类型保留。\n\n客户端流式传输编码示例：\n```\n1 <length> <message-bytes> 1 <length> <message-bytes>  … EOF\n```\n\n服务器流式传输编码示例：\n```\n1 <length> <message-bytes>  … 2 <length> <status-bytes> EOF\n```\n\n线级编码：StreamBody 的定义仅在其为字段“messages”分配 tag-id 时才有意义，而“status”对于正常消息将采用 1-2 字节的 varint 编码，因此总的编码开销为每条消息 2-3 个字节\n\n需要添加可选的填充字段，才能支持使用 base64 编码的流：\n```\nmessage StreamBody {\n  repeated bytes message = 1;\n  google.rpc.Status status = 2;\n  repeated bytes padding = 15;   // max one-byte tag-id: xxx01111\n}\n```\n\n错误消息应作为 JSON 或 protobuf 数组的最后一个元素附加，其格式与常规消息相同。\n\n## 状态管理\n\n适用于客户端或服务器的任何 HTTP 版本中都很好地定义了半关闭行为，旨在向另一端发送主体已完成的信号。\n\n特别是，客户端代码在等待响应时可以自由完成请求。与之类似，当请求主体仍在写入服务器时，客户端可能会看到完成的响应。HTTP 标准要求客户端在以意外方式完成响应时（通常具有错误状态）中止或完成请求。这就是说，在正常情况下，服务器不应在客户端仍在发送请求时完成响应。\n\n### 取消\n\n通过取消支持，客户端能够在请求或响应仍在等待处理时中止请求。\n\nHTTP/1.* 客户端没有可靠的取消支持，因为客户端可在请求完成后随时关闭 TCP 连接，而不会中止请求/响应事务。采用 HTTP/1.1 的 TCP FIN 不应被解释为取消，即使连接被标记为保持 keep-alive (Connection: Keep-Alive) 也是如此。\n\n但在客户端关闭 TCP 连接后，如果服务器尝试将任何数据写入客户端，则会生成 RST，这会触发取消。\n\n另请注意，取消也是非流式传输 API 存在的问题。当响应涉及长轮询并且因此导致连接长时间保持空闲时，此问题尤其明显。\n\nSPDY、HTTP/2 和 QUIC 支持显式取消，尤其是与 go-away 消息结合使用。\n\n### Keep-alive\n\n通过 Keep-alive 支持，客户端或服务器能够检测到失败的对等体，即使在出现丢包或网络故障的情况下也是如此。\n\nHTTP/1.1 不提供 keep-alive 支持，因为 TCP keep-alive 不是一种可行的方法。\n\nQUIC 或 HTTP/2 提供特殊控制消息，旨在实现由应用（包括浏览器）提供的 keep-alive 支持。\n\n但是，实现可靠的 keep-alive 和故障检测将可能需要有一个客户端库，加上必要的服务器端支持：如果依赖将基本 HTTP 作为通信协议，通过互联网进行长期流式传输通常容易出错。\n\n\n## 流控制\n\n流控制支持要求客户端将传输级流控制事件传播到客户端应用。实际的机制取决于客户端应用所使用的 HTTP 客户端 API 执行机制。例如，为了防止客户端或服务器过载，您需要使用显式流控制支持阻塞写入和读取或者非阻塞读取和写入，以便应用处理和遵循流控制事件。\n\nHTTP/1.1 依赖于 TCP 流控制。\n\nSPDY 和 HTTP/2 在流级别具有自己的流控制，由于请求通过单个 TCP 连接进行多路复用，因此它们在连接级别进一步受到 TCP 流控制的限制。\n\nQUIC 在 UDP 上运行，因此可以完全自行管理流控制。","tags":["http","Google API"],"categories":["http"]},{"title":"git 提交信息规范","url":"/2021/04/11/git-commit-message/","content":"\n## 您可以遵循的Git commit消息约定！\n\n典型的git commit消息像下面这样\n```\n<type>(<scope>): <subject>\n```\n\n### “类型”必须是以下提到的以下内容之一！\n\n<!-- more -->\n\n* build: 建立相关的更改（例如：与npm相关/添加外部依赖项）\n* chore: 外部用户看不到的代码更改（例如：更改为.gitignore文件或.prettierrc文件）\n* feat: 新特性\n* fix: bug修复\n* docs: 与文档相关的改变\n* refactor: 既不修复错误也不添加功能的代码。 （例如：您可以在语义更改（例如重命名变量/函数名称）时使用此功能）\n* perf: 可以提高性能的代码\n* style: 有关样式的代码\n* test: 添加新测试或对现有测试进行更改\n* update: 更新\n* upgrade: 升级\n* sponsors: 赞助相关\n\n### \"scope\" 是可选的\n\n* scope 必须是名词，并且代表代码库部分的部分\n* [请参阅此链接以获取与scope相关的示例](http://karma-runner.github.io/1.0/dev/git-commit-msg.html)\n\n### \"subject\"\n\n* 使用命令式，现在时(如： 使用\"add\" 代替 \"added\" 或 \"adds\")\n* 不要使用 \".\" 结尾\n* 不要使用首字母大写方式\n\n**[请参阅此链接以获取更多实用的提交消息示例](https://github.com/eslint/eslint/commits/master)**\n\n### References:\n* https://www.conventionalcommits.org/en/v1.0.0/\n* https://gist.github.com/joshbuchea/6f47e86d2510bce28f8e7f42ae84c716\n* https://github.com/fteem/git-semantic-commits","tags":["git"],"categories":["mysql"]},{"title":"Hello World","url":"/2021/03/27/hello-world/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n<!-- more -->\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n"},{"title":"http vs https","url":"/2021/03/27/https/","content":"Welcome to [Hexo](https://hexo.io/)! This is your very first post. Check [documentation](https://hexo.io/docs/) for more info. If you get any problems when using Hexo, you can find the answer in [troubleshooting](https://hexo.io/docs/troubleshooting.html) or you can ask me on [GitHub](https://github.com/hexojs/hexo/issues).\n\n## Quick Start\n\n### Create a new post\n\n``` bash\n$ hexo new \"My New Post\"\n```\n\nMore info: [Writing](https://hexo.io/docs/writing.html)\n\n<!-- more -->\n\n### Run server\n\n``` bash\n$ hexo server\n```\n\nMore info: [Server](https://hexo.io/docs/server.html)\n\n### Generate static files\n\n``` bash\n$ hexo generate\n```\n\nMore info: [Generating](https://hexo.io/docs/generating.html)\n\n### Deploy to remote sites\n\n``` bash\n$ hexo deploy\n```\n\nMore info: [Deployment](https://hexo.io/docs/one-command-deployment.html)\n"},{"title":"golang-gmp","url":"/2021/03/27/golang/","content":"\nthis is golang new test\n","categories":["golang"]},{"title":"索引为何使用B+树","url":"/2020/10/12/索引为何使用B+树/","content":"\n## 问题思考\n\n数据库索引的数据结构有很多种，比如：哈希索引、平衡二叉树索引、B树索引、B+树索引等等。\n\n目前最流行的是B+树索引，那大家有没有想过为什么是B+树索引最流行，为什么其他索引应用不广泛\n\n## 哈希索引\n\n<!-- more -->\n\nhash大家应该非常的熟悉，就是我们老生常谈的HashMap里用到的技术。Hash索引其检索效率非常高，索引的检索可以一次定位。\n\n既然Hash索引的效率这么高，为什么都用Hash索引而还要使用B-Tree索引呢?\n\n这是因为虽然Hash索引效率高，但是Hash索引本身由于其特殊性也带来了很多限制和弊端，主要有以下这些：\n\n### 1. 原因一：\n\n**Hash索引不能使用范围查询**\n\nHash索引仅仅能满足\"=\",\"IN\"和\"<=>\"查询(注意<>和＜＝＞是不同的操作），不能使用范围查询，例如WHERE price > 100。\n\n由于Hash索引比较的是进行Hash运算之后的Hash值，所以它只能用于等值的过滤，不能用于基于范围的过滤。\n\n### 2. 原因二：\n\n**Hash索引不能利用部分索引键查询。**\n\n对于复合索引，Hash索引在计算Hash值的时候，是组合索引键合并后再一起计算Hash值，而不是单独计算Hash值。\n\n所以通过复合索引的前面一个或几个索引键进行查询的时候，Hash索引也无法被利用。\n\n### 3. 原因三：\n\n**Hash索引在任何时候都不能避免表扫描。**\n\nHash索引是将索引键通过Hash运算之后，将 Hash运算结果的Hash值和所对应的行指针信息存放于一个Hash表中。\n\n由于不同索引键存在相同Hash值，所以无法从Hash索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。\n\n\n## 平衡二叉树索引\n\n平衡二叉树的结构特点：\n\n![mysql_avl_tree](https://luckylsx.github.io/images/mysql/mysql_avl_tree.png)\n\n又称 AVL树。它除了具备二叉查找树的基本特征之外，还具有一个非常重要的特点：它的左子树和右子树都是平衡二叉树。\n\n且左子树和右子树的深度之差的绝对值（平衡因子 ）不超过1。也就是说AVL树每个节点的平衡因子只可能是-1、0和1（左子树高度减去右子树高度）。\n\n### 被淘汰的原因:\n\n- 树的高度过高，高度越高，查找速度越慢\n- 他支持范围查找，但是他需要在进行回旋查找\n\n比如我要找到大于5的数据\n\n第一步我先定位到5，然后在树上按照二叉树规则去回旋查找大于5其他数据6、7、8、9、10。。。\n\n如果大于5的数据很多，那速度是很慢的。\n\n\n## B树索引\n\n![mysql_b_tree](https://luckylsx.github.io/images/mysql/mysql_b_tree.png)\n\n大家可以看到B树和二叉树最大的区别在于：它一个节点可以存储两个值，这就意味着它的树高度，比二叉树的高度更低，它的查询速度就更快。这是他的优点\n\n那为什么最终还是不用它呢，还是因为他在范围查找的时候，存在回旋查询的问题。同样order by排序的时候效率也很低，因为要把树上的数据手动排序一遍。\n\n## 终极大佬：B+树:\n\n![mysql_b_plus_tree](https://luckylsx.github.io/images/mysql/mysql_b_plus_tree.png)\n\n它是B数的升级版，B+树相比B树，新增叶子节点与非叶子节点关系。\n\n叶子节点中包含了key和value，key存储的是1-10这些数字，value存储的是数据存储地址，非叶子节点中只是包含了key，不包含value。\n\n所有相邻的叶子节点包含非叶子节点，使用链表进行结合，有一定顺序排序，从而范围查询效率非常高\n\n### 比如我们要查找大于5的数据：\n\n- 首先我们定位到5的位置\n- 然后直接将5后面的数据全部拿出来即可，因为这是有序链表，已经排好序了\n\n我们在order by排序的时候为什么要使用索引进行排序，原因就在这。","tags":["mysql","B+树","hash"],"categories":["mysql"]},{"title":"MySQL数据库设计规范","url":"/2020/04/13/the-Mysql-Standards-Recommendation/","content":"\n## 目录\n\n```\n1. 规范背景与目的\t\n\n2. 设计规范\n\n2.1 数据库设计\t\n\n2.1.1 库名\t\n2.1.2 表结构\t\n2.1.3 列数据类型优化\t\n2.1.4 索引设计\t\n2.1.5 分库分表、分区表\t\n2.1.6 字符集\t\n2.1.7 程序DAO层设计建议\t\n2.1.8 一个规范的建表语句示例\t\n\n2.2 SQL编写\t\n\n2.2.1 DML语句\t\n2.2.2 多表连接\t\n2.2.3 事务\t\n2.2.4 排序和分组\t\n2.2.5 线上禁止使用的SQL语句\n```\n\n<!-- more -->\n\n\n## 1. 规范背景与目的\nMySQL数据库与 Oracle、 SQL Server 等数据库相比，有其内核上的优势与劣势。我们在使用MySQL数据库的时候需要遵循一定规范，扬长避短。本规范旨在帮助或指导RD、QA、OP等技术人员做出适合线上业务的数据库设计。在数据库变更和处理流程、数据库表设计、SQL编写等方面予以规范，从而为公司业务系统稳定、健康地运行提供保障。\n\n## 2. 设计规范\n\n### 2.1 数据库设计\n以下所有规范会按照【高危】、【强制】、【建议】三个级别进行标注，遵守优先级从高到低。\n\n对于不满足【高危】和【强制】两个级别的设计，DBA会强制打回要求修改。\n\n#### 2.1.1 库名\n1.【强制】库的名称必须控制在32个字符以内，相关模块的表名与表名之间尽量提现join的关系，如user表和user_login表。\n\n2.【强制】库的名称格式：业务系统名称_子系统名，同一模块使用的表名尽量使用统一前缀。\n\n3.【强制】一般分库名称命名格式是库通配名_编号，编号从0开始递增，比如wenda_001以时间进行分库的名称格式是“库通配名_时间”\n\n4.【强制】创建数据库时必须显式指定字符集，并且字符集只能是utf8或者utf8mb4。创建数据库SQL举例：create database db1 default character set utf8;。\n\n#### 2.1.2 表结构\n\n1.【强制】表和列的名称必须控制在32个字符以内，表名只能使用字母、数字和下划线，一律小写。\n\n2.【强制】表名要求模块名强相关，如师资系统采用”sz”作为前缀，渠道系统采用”qd”作为前缀等。\n\n3.【强制】创建表时必须显式指定字符集为utf8或utf8mb4。\n\n4.【强制】创建表时必须显式指定表存储引擎类型，如无特殊需求，一律为InnoDB。当需要使用除InnoDB/MyISAM/Memory以外的存储引擎时，必须通过DBA审核才能在生产环境中使用。因为Innodb表支持事务、行锁、宕机恢复、MVCC等关系型数据库重要特性，为业界使用最多的MySQL存储引擎。而这是其他大多数存储引擎不具备的，因此首推InnoDB。\n\n5.【强制】建表必须有comment\n\n6.【建议】建表时关于主键：(1)强制要求主键为id，类型为int或bigint，且为auto_increment。(2)标识表里每一行主体的字段不要设为主键，建议设为其他字段如user_id，order_id等，并建立unique key索引（可参考cdb.teacher表设计）。因为如果设为主键且主键值为随机插入，则会导致innodb内部page分裂和大量随机I/O，性能下降。\n\n7.【建议】核心表（如用户表，金钱相关的表）必须有行数据的创建时间字段create_time和最后更新时间字段update_time，便于查问题。\n\n8.【建议】表中所有字段必须都是NOT NULL属性，业务可以根据需要定义DEFAULT值。因为使用NULL值会存在每一行都会占用额外存储空间、数据迁移容易出错、聚合函数计算结果偏差等问题。\n\n9.【建议】建议对表里的blob、text等大字段，垂直拆分到其他表里，仅在需要读这些对象的时候才去select。\n\n10.【建议】反范式设计：把经常需要join查询的字段，在其他表里冗余一份。如user_name属性在user_account，user_login_log等表里冗余一份，减少join查询。\n\n11.【强制】中间表用于保留中间结果集，名称必须以tmp_开头。备份表用于备份或抓取源表快照，名称必须以bak_开头。中间表和备份表定期清理。\n\n12.【强制】对于超过100W行的大表进行alter table，必须经过DBA审核，并在业务低峰期执行。因为alter table会产生表锁，期间阻塞对于该表的所有写入，对于业务可能会产生极大影响。\n\n#### 2.1.3 列数据类型优化\n\n1.【建议】表中的自增列（auto_increment属性），推荐使用bigint类型。因为无符号int存储范围为-2147483648~2147483647（大约21亿左右），溢出后会导致报错。\n\n2.【建议】业务中选择性很少的状态status、类型type等字段推荐使用tinytint或者smallint类型节省存储空间。\n\n3.【建议】业务中IP地址字段推荐使用int类型，不推荐用char(15)。因为int只占4字节，可以用如下函数相互转换，而char(15)占用至少15字节。一旦表数据行数到了1亿，那么要多用1.1G存储空间。SQL：select inet_aton('192.168.2.12'); select inet_ntoa(3232236044); PHP: ip2long(‘192.168.2.12’); long2ip(3530427185);\n\n4.【建议】不推荐使用enum，set。因为它们浪费空间，且枚举值写死了，变更不方便。推荐使用tinyint或smallint。\n\n5.【建议】不推荐使用blob，text等类型。它们都比较浪费硬盘和内存空间。在加载表数据时，会读取大字段到内存里从而浪费内存空间，影响系统性能。建议和PM、RD沟通，是否真的需要这么大字段。Innodb中当一行记录超过8098字节时，会将该记录中选取最长的一个字段将其768字节放在原始page里，该字段余下内容放在overflow-page里。不幸的是在compact行格式下，原始page和overflow-page都会加载。\n\n6.【建议】存储金钱的字段，建议用int，程序端乘以100和除以100进行存取。因为int占用4字节，而double占用8字节，空间浪费。\n\n7.【建议】文本数据尽量用varchar存储。因为varchar是变长存储，比char更省空间。MySQL server层规定一行所有文本最多存65535字节，因此在utf8字符集下最多存21844个字符，超过会自动转换为mediumtext字段。而text在utf8字符集下最多存21844个字符，mediumtext最多存2^24/3个字符，longtext最多存2^32个字符。一般建议用varchar类型，字符数不要超过2700。\n\n8.【建议】时间类型尽量选取timestamp。因为datetime占用8字节，timestamp仅占用4字节，但是范围为1970-01-01 00:00:01到2038-01-01 00:00:00。更为高阶的方法，选用int来存储时间，使用SQL函数unix_timestamp()和from_unixtime()来进行转换。\n\n详细存储大小参加下图：\n\n![mysql_time_base](https://luckylsx.github.io/images/mysql/mysql_time_type.png)\n\n#### 2.1.4 索引设计\n\n1.【强制】InnoDB表必须主键为id int/bigint auto_increment,且主键值禁止被更新。\n\n2.【建议】主键的名称以“pk_”开头，唯一键以“uk_”或“uq_”开头，普通索引以“idx_”开头，一律使用小写格式，以表名/字段的名称或缩写作为后缀。\n\n3.【强制】InnoDB和MyISAM存储引擎表，索引类型必须为BTREE；MEMORY表可以根据需要选择HASH或者BTREE类型索引。\n\n4.【强制】单个索引中每个索引记录的长度不能超过64KB。\n\n5.【建议】单个表上的索引个数不能超过7个。\n\n6.【建议】在建立索引时，多考虑建立联合索引，并把区分度最高的字段放在最前面。如列userid的区分度可由select count(distinct userid)计算出来。\n\n7.【建议】在多表join的SQL里，保证被驱动表的连接列上有索引，这样join执行效率最高。\n\n8.【建议】建表或加索引时，保证表里互相不存在冗余索引。对于MySQL来说，如果表里已经存在key(a,b)，则key(a)为冗余索引，需要删除。\n\n#### 2.1.5 分库分表、分区表\n\n1.【强制】分区表的分区字段（partition-key）必须有索引，或者是组合索引的首列。\n\n2.【强制】单个分区表中的分区（包括子分区）个数不能超过1024。\n\n3.【强制】上线前RD或者DBA必须指定分区表的创建、清理策略。\n\n4.【强制】访问分区表的SQL必须包含分区键。\n\n5.【建议】单个分区文件不超过2G，总大小不超过50G。建议总分区数不超过20个。\n\n6.【强制】对于分区表执行alter table操作，必须在业务低峰期执行。\n\n7.【强制】采用分库策略的，库的数量不能超过1024\n\n8.【强制】采用分表策略的，表的数量不能超过4096\n\n9.【建议】单个分表不超过500W行，ibd文件大小不超过2G，这样才能让数据分布式变得性能更佳。\n\n10.【建议】水平分表尽量用取模方式，日志、报表类数据建议采用日期进行分表。\n\n#### 2.1.6 字符集\n\n1.【强制】数据库本身库、表、列所有字符集必须保持一致，为utf8或utf8mb4。\n\n2.【强制】前端程序字符集或者环境变量中的字符集，与数据库、表的字符集必须一致，统一为utf8。\n\n#### 2.1.7 程序层DAO设计建议\n\n1.【建议】新的代码不要用model，推荐使用手动拼SQL+绑定变量传入参数的方式。因为model虽然可以使用面向对象的方式操作db，但是其使用不当很容易造成生成的SQL非常复杂，且model层自己做的强制类型转换性能较差，最终导致数据库性能下降。\n\n2.【建议】前端程序连接MySQL或者redis，必须要有连接超时和失败重连机制，且失败重试必须有间隔时间。\n\n3.【建议】前端程序报错里尽量能够提示MySQL或redis原生态的报错信息，便于排查错误。\n\n4.【建议】对于有连接池的前端程序，必须根据业务需要配置初始、最小、最大连接数，超时时间以及连接回收机制，否则会耗尽数据库连接资源，造成线上事故。\n\n5.【建议】对于log或history类型的表，随时间增长容易越来越大，因此上线前RD或者DBA必须建立表数据清理或归档方案。\n\n6.【建议】在应用程序设计阶段，RD必须考虑并规避数据库中主从延迟对于业务的影响。尽量避免从库短时延迟（20秒以内）对业务造成影响，建议强制一致性的读开启事务走主库，或更新后过一段时间再去读从库。\n\n7.【建议】多个并发业务逻辑访问同一块数据（innodb表）时，会在数据库端产生行锁甚至表锁导致并发下降，因此建议更新类SQL尽量基于主键去更新。\n\n8.【建议】业务逻辑之间加锁顺序尽量保持一致，否则会导致死锁。\n\n9.【建议】对于单表读写比大于10:1的数据行或单个列，可以将热点数据放在缓存里（如mecache或redis），加快访问速度，降低MySQL压力。\n\n#### 2.1.8 一个规范的建表语句示例\n\n**一个较为规范的建表语句为：**\n\n```\nCREATE TABLE user (\n  `id` bigint(11) NOT NULL AUTO_INCREMENT,\n  `user_id` bigint(11) NOT NULL COMMENT ‘用户id’\n  `username` varchar(45) NOT NULL COMMENT '真实姓名',\n  `email` varchar(30) NOT NULL COMMENT ‘用户邮箱’,\n  `nickname` varchar(45) NOT NULL COMMENT '昵称',\n  `avatar` int(11) NOT NULL COMMENT '头像',\n  `birthday` date NOT NULL COMMENT '生日',\n  `sex` tinyint(4) DEFAULT '0' COMMENT '性别',\n  `short_introduce` varchar(150) DEFAULT NULL COMMENT '一句话介绍自己，最多50个汉字',\n  `user_resume` varchar(300) NOT NULL COMMENT '用户提交的简历存放地址',\n  `user_register_ip` int NOT NULL COMMENT ‘用户注册时的源ip’,\n  `create_time` timestamp NOT NULL COMMENT ‘用户记录创建的时间’,\n  `update_time` timestamp NOT NULL COMMENT ‘用户资料修改的时间’,\n  `user_review_status` tinyint NOT NULL COMMENT ‘用户资料审核状态，1为通过，2为审核中，3为未通过，4为还未提交审核’,\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `idx_user_id` (`user_id`),\n  KEY `idx_username`(`username`),\n  KEY `idx_create_time`(`create_time`,`user_review_status`)\n) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='网站用户基本信息';\n```\n\n### 2.2 SQL编写\n\n#### 2.2.1 DML语句\n\n1.【强制】SELECT语句必须指定具体字段名称，禁止写成*。因为select *会将不该读的数据也从MySQL里读出来，造成网卡压力。且表字段一旦更新，但model层没有来得及更新的话，系统会报错。\n\n2.【强制】insert语句指定具体字段名称，不要写成insert into t1 values(…)，道理同上。\n\n3.【建议】insert into…values(XX),(XX),(XX)…。这里XX的值不要超过5000个。值过多虽然上线很很快，但会引起主从同步延迟。\n\n4.【建议】SELECT语句不要使用UNION，推荐使用UNION ALL，并且UNION子句个数限制在5个以内。因为union all不需要去重，节省数据库资源，提高性能。\n\n5.【建议】in值列表限制在500以内。例如select… where userid in(….500个以内…)，这么做是为了减少底层扫描，减轻数据库压力从而加速查询。\n\n6.【建议】事务里批量更新数据需要控制数量，进行必要的sleep，做到少量多次。\n\n7.【强制】事务涉及的表必须全部是innodb表。否则一旦失败不会全部回滚，且易造成主从库同步终端。\n\n8.【强制】写入和事务发往主库，只读SQL发往从库。\n\n9.【强制】除静态表或小表（100行以内），DML语句必须有where条件，且使用索引查找。\n\n10.【强制】生产环境禁止使用hint，如sql_no_cache，force index，ignore key，straight join等。因为hint是用来强制SQL按照某个执行计划来执行，但随着数据量变化我们无法保证自己当初的预判是正确的，因此我们要相信MySQL优化器！\n\n11.【强制】where条件里等号左右字段类型必须一致，否则无法利用索引。\n\n12.【建议】SELECT|UPDATE|DELETE|REPLACE要有WHERE子句，且WHERE子句的条件必需使用索引查找。\n\n13.【强制】生产数据库中强烈不推荐大表上发生全表扫描，但对于100行以下的静态表可以全表扫描。查询数据量不要超过表行数的25%，否则不会利用索引。\n\n14.【强制】WHERE 子句中禁止只使用全模糊的LIKE条件进行查找，必须有其他等值或范围查询条件，否则无法利用索引。\n\n15.【建议】索引列不要使用函数或表达式，否则无法利用索引。如where length(name)='Admin'或where user_id+2=10023。\n\n16.【建议】减少使用or语句，可将or语句优化为union，然后在各个where条件上建立索\n\n17.【建议】分页查询，当limit起点较高时，可先用过滤条件进行过滤。如select a,b,c from t1 limit 10000,20;优化为: select a,b,c from t1 where id>10000 limit 20;。\n\n#### 2.2.2 多表连接\n\n1.【强制】禁止跨db的join语句。因为这样可以减少模块间耦合，为数据库拆分奠定坚实基础。\n\n2.【强制】禁止在业务的更新类SQL语句中使用join，比如update t1 join t2…。\n\n3.【建议】不建议使用子查询，建议将子查询SQL拆开结合程序多次查询，或使用join来代替子查询。\n\n4.【建议】线上环境，多表join不要超过3个表。\n\n5.【建议】多表连接查询推荐使用别名，且SELECT列表中要用别名引用字段，数据库.表格式，如select a from db1.table1 alias1 where …。\n\n6.【建议】在多表join中，尽量选取结果集较小的表作为驱动表，来join其他表。\n\n#### 2.2.3 事务\n\n1.【建议】事务中INSERT|UPDATE|DELETE|REPLACE语句操作的行数控制在2000以内，以及WHERE子句中IN列表的传参个数控制在500以内。\n\n2.【建议】批量操作数据时，需要控制事务处理间隔时间，进行必要的sleep，一般建议值5-10秒。\n\n3.【建议】对于有auto_increment属性字段的表的插入操作，并发需要控制在200以内。\n\n4.【强制】程序设计必须考虑“数据库事务隔离级别”带来的影响，包括脏读、不可重复读和幻读。线上建议事务隔离级别为repeatable-read。\n\n5.【建议】事务里包含SQL不超过5个（支付业务除外）。因为过长的事务会导致锁数据较久，MySQL内部缓存、连接消耗过多等雪崩问题。\n\n6.【建议】事务里更新语句尽量基于主键或unique key，如update … where id=XX; 否则会产生间隙锁，内部扩大锁定范围，导致系统性能下降，产生死锁。\n\n7.【建议】尽量把一些典型外部调用移出事务，如调用webservice，访问文件存储等，从而避免事务过长。\n\n8.【建议】对于MySQL主从延迟严格敏感的select语句，请开启事务强制访问主库。\n\n#### 2.2.4 排序和分组\n\n1.【建议】减少使用order by，和业务沟通能不排序就不排序，或将排序放到程序端去做。order by、group by、distinct这些语句较为耗费CPU，数据库的CPU资源是极其宝贵的。\n\n2.【建议】order by、group by、distinct这些SQL尽量利用索引直接检索出排序好的数据。如where a=1 order by可以利用key(a,b)。\n\n3.【建议】包含了order by、group by、distinct这些查询的语句，where条件过滤出来的结果集请保持在1000行以内，否则SQL会很慢。\n\n#### 2.2.5 线上禁止使用的SQL语句\n\n1.【高危】禁用update|delete t1 … where a=XX limit XX; 这种带limit的更新语句。因为会导致主从不一致，导致数据错乱。建议加上order by PK。\n\n2.【高危】禁止使用关联子查询，如update t1 set … where name in(select name from user where…);效率极其低下。\n\n3.【强制】禁用procedure、function、trigger、views、event、外键约束。因为他们消耗数据库资源，降低数据库实例可扩展性。推荐都在程序端实现。\n\n4.【强制】禁用insert into …on duplicate key update…在高并发环境下，会造成主从不一致。\n\n5.【强制】禁用insert into …on duplicate key update…在高并发环境下，会造成主从不一致。\n\n","tags":["mysq"],"categories":["MYSQL"]},{"title":"一条sql语句的执行过程","url":"/2020/01/14/一条sql语句的执行过程/","content":"\n比如：\n```\nmysql> select * from T where ID=10；\n```\n要想知道这条语句在 MySQL 内部的执行过程，需要把 MySQL 拆解一下看看里面都有哪些“零件”，希望借由这个拆解过程，让你对 MySQL 有更深入的理解。这样当我们碰到 MySQL 的一些异常或者问题时，就能够直戳本质，更为快速地定位并解决问题。\n\n<!-- more -->\n\n下面我给出的是 MySQL 的基本架构示意图，从中你可以清楚地看到 SQL 语句在 MySQL 的各个功能模块中的执行过程。\n\nMySQL 的逻辑架构图\n\n![mysql_base](/images/mysql/mysql_base.png)\n\n大体来说，MySQL 可以分为 Server 层和存储引擎层。\n\nServer 层包括连接器、查询缓存、分析器、优化器、执行器等，涵盖 MySQL 的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。\n\n而存储引擎层负责数据的存储和提取。其架构模式是插件式的，支持 InnoDB、MyISAM、Memory 等多个存储引擎。现在最常用的存储引擎是 InnoDB，它从 MySQL 5.5.5 版本开始成为了默认存储引擎。\n\n也就是说，你执行 create table 建表的时候，如果不指定引擎类型，默认使用的就是 InnoDB。不过，你也可以通过指定存储引擎的类型来选择别的引擎，比如在 create table 语句中使用 engine=memory, 来指定使用内存引擎创建表。不同存储引擎的表数据存取方式不同，支持的功能也不同。\n\n从图中不难看出，不同的存储引擎共用一个Server 层，也就是从连接器到执行器的部分。你可以先对每个组件的名字有个印象，接下来我会结合开头提到的那条 SQL 语句，带你走一遍整个执行流程，依次看下每个组件的作用。\n\n连接器\n第一步，你会先连接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令一般是这么写的：\n\n```\nmysql -h$ip -P$port -u$user -p\n```\n\n输完命令之后，你就需要在交互对话里面输入密码。虽然密码也可以直接跟在 -p 后面写在命令行中，但这样可能会导致你的密码泄露。如果你连的是生产服务器，强烈建议你不要这么做。\n\n连接命令中的 mysql 是客户端工具，用来跟服务端建立连接。在完成经典的 TCP 握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。\n\n- 如果用户名或密码不对，你就会收到一个\"Access denied for user\"的错误，然后客户端程序结束执行。\n- 如果用户名密码认证通过，连接器会到权限表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时读到的权限。\n\n这就意味着，一个用户成功建立连接后，即使你用管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成后，只有再新建的连接才会使用新的权限设置。\n\n连接完成后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在 show processlist 命令中看到它。文本中这个图是 show processlist 的结果，其中的 Command 列显示为“Sleep”的这一行，就表示现在系统里面有一个空闲连接。\n\n![mysql_processlist](/images/mysql/mysql_processlist.png)\n\n客户端如果太长时间没动静，连接器就会自动将它断开。这个时间是由参数 wait_timeout 控制的，默认值是 8 小时。\n\n如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒： Lost connection to MySQL server during query。这时候如果你要继续，就需要重连，然后再执行请求了。\n\n数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一直使用同一个连接。短连接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。\n\n建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。\n\n但是全部使用长连接后，你可能会发现，有些时候 MySQL 占用内存涨得特别快，这是因为MySQL 在执行过程中临时使用的内存是管理在连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累积下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是 MySQL 异常重启了。\n\n怎么解决这个问题呢？你可以考虑以下两种方案。\n\n1.定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。\n\n2.如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行 mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。\n\n**查询缓存**\n\n连接建立完成后，你就可以执行 select 语句了。执行逻辑就会来到第二步：查询缓存。\n\nMySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。key 是查询的语句，value 是查询的结果。如果你的查询能够直接在这个缓存中找到 key，那么这个 value 就会被直接返回给客户端。\n\n如果语句不在查询缓存中，就会继续后面的执行阶段。执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存，MySQL 不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。\n\n**但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。**\n\n查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。对于更新压力大的数据库来说，查询缓存的命中率会非常低。除非你的业务就是有一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。\n\n好在 MySQL 也提供了这种“按需使用”的方式。你可以将参数 query_cache_type 设置成 DEMAND，这样对于默认的 SQL 语句都不使用查询缓存。而对于你确定要使用查询缓存的语句，可以用 SQL_CACHE 显式指定，像下面这个语句一样：\n\n```\nselect SQL_CACHE * from T where ID=10\n```\n\n需要注意的是，MySQL 8.0 版本直接将查询缓存的整块功能删掉了，也就是说 8.0 开始彻底没有这个功能了。\n\n**分析器**\n\n如果没有命中查询缓存，就要开始真正执行语句了。首先，MySQL 需要知道你要做什么，因此需要对 SQL 语句做解析。\n\n分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。\n\nMySQL 从你输入的\"select\"这个关键字识别出来，这是一个查询语句。它也要把字符串 “T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。\n\n做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。\n\n如果你的语句不对，就会收到 “You have an error in your SQL syntax”的错误提醒，比如下面这个语句 select 少打了开头的字母“s”。\n\n```\nmysql> elect * from t where ID=1;\n```\n\n```\nERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'elect * from t where ID=1' at line 1\n```\n\n一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接“use near”的内容。\n\n**优化器**\n\n经过了分析器，MySQL 就知道你要做什么了。在开始执行之前，还要先经过优化器的处理。\n\n优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的 join:\n\n```\nselect * from t1 join t2 using(ID) where t1.c=10 and t2.d=20\n```\n\n- 既可以先从表 t1 里面取出 c=10 的记录的 ID 值，再根据 ID 值关联到表 t2，再判断 t2 里面 d 的值是否等于 20。\n- 也可以先从表 t2 里面取出 d=20 的记录的 ID 值，再根据 ID 值关联到 t1，再判断 t1 里面 c 的值是否等于 10。\n\n这两种执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。\n\n优化器阶段完成后，这个语句的执行方案就确定下来了，然后进入执行器阶段。\n\n**执行器**\n\nMySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。\n\n开始执行的时候，要先判断一下你对这个表 T 有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示 (在工程实现上，如果命中查询缓存，会在查询缓存返回结果的时候，做权限验证。查询也会在优化器之前调用 precheck 验证权限)。\n\n```\nselect * from t1 where id=10;\nERROR 1142(42000) SELECT commend denied to user 'b'@'localhost' for table 'T'\n```\n\n如果有权限，就打开表继续执行。打开表的时候，执行器就会根据表的引擎定义，去使用这个引擎提供的接口\n\n比如我们这个例子中的表 T 中，ID 字段没有索引，那么执行器的执行流程是这样的：\n \n1.调用 InnoDB 引擎接口取这个表的第一行，判断 ID 值是不是 10，如果不是则跳过，如果是则将这行存在结果集中；\n2.调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。\n3.执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集作为结果集返回给客户端。\n\n至此，这个语句就执行完成了。\n\n对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。\n\n你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。\n\n在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相的。\n\n\n\n\n\n\n\n\n\n\n\n\n","tags":["mysql"],"categories":["MYSQL"]}]